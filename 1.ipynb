{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'during the training the sequential model recieve the data via the \"fit\" function so we have to understand the structure\\nof the fit function--understand about the fit function-- and what are the data types that are used for the inputs in\\nfor fit array tensor dictionary dataset etc ------ both x and y have same the data format if x is a tensor then y also a \\n tensor'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"--------------------------------------data creation and data preprocessing-------------------------------------------\"\"\"\n",
    "\n",
    "\"\"\"during the training the sequential model recieve the data via the \"fit\" function so we have to understand the structure\n",
    "of the fit function--understand about the fit function-- and what are the data types that are used for the inputs in\n",
    "for fit array tensor dictionary dataset etc ------ both x and y have same the data format if x is a tensor then y also a \n",
    " tensor\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"drug was tested on individuals from 13 to 100 ages in a clinic using 2100 people and half were under 65 years and half \\nwere equal or less than 65.95% of patients above 65 face side effects and 95% of below 65 doesn't face side effects\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing necessary libraries \n",
    "\n",
    "import numpy as np\n",
    "from random import randint \n",
    "from sklearn.utils import shuffle #for data shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler#preprocessor \n",
    "\n",
    "\"\"\"drug was tested on individuals from 13 to 100 ages in a clinic using 2100 people and half were under 65 years and half \n",
    "were equal or less than 65.95% of patients above 65 face side effects and 95% of below 65 doesn't face side effects\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here by rounding off we assume that 50 of yougers have side effects while other 1000 have no side effects while 1000 \\nolders   have side effects and 50 have no side effects where 2100/2 = 1050'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating two lists to get train data \n",
    "train_samples = []#x values\n",
    "train_labels = []#y values\n",
    "\"\"\"here by rounding off we assume that 50 of yougers have side effects while other 1000 have no side effects while 1000 \n",
    "olders   have side effects and 50 have no side effects where 2100/2 = 1050\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here it go we have made a data set'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get 50 people in both older and younger \n",
    "for i in range (50):\n",
    "    # 5% of youngers who have side effects\n",
    "    random_younger = randint(13, 64)#this generates a random number between 13 and 64 \n",
    "    train_samples.append(random_younger)#assing random value to the list\n",
    "    train_labels.append(1)#as having side effects set to 1\n",
    "    \n",
    "    #5% of olders who haven't side effects\n",
    "    random_older = randint(65, 100)#this generates a random number between 13 and 64 \n",
    "    train_samples.append(random_older)#assing random value to the list\n",
    "    train_labels.append(0)#as not having side effects set to 0\n",
    "    \n",
    "#to get 1000 people in both older and younger \n",
    "for i in range (1000):\n",
    "    # 95% of youngers who donot have side effects\n",
    "    random_younger = randint(13, 64)#this generates a random number between 13 and 64 \n",
    "    train_samples.append(random_younger)#assing random value to the list\n",
    "    train_labels.append(0)#as having side effects set to 1\n",
    "    \n",
    "    #95% of olders who haven't side effects\n",
    "    random_older = randint(65, 100)#this generates a random number between 13 and 64 \n",
    "    train_samples.append(random_older)#assing random value to the list\n",
    "    train_labels.append(1)#as not having side effects set to 0    \n",
    "    \n",
    "\"\"\"here it go we have made a data set\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "98\n",
      "48\n",
      "68\n",
      "27\n",
      "85\n",
      "30\n",
      "91\n",
      "53\n",
      "67\n",
      "20\n",
      "89\n",
      "25\n",
      "97\n",
      "54\n",
      "84\n",
      "44\n",
      "68\n",
      "33\n",
      "83\n",
      "29\n",
      "86\n",
      "64\n",
      "75\n",
      "29\n",
      "89\n",
      "61\n",
      "65\n",
      "42\n",
      "81\n",
      "27\n",
      "73\n",
      "50\n",
      "76\n",
      "37\n",
      "72\n",
      "39\n",
      "87\n",
      "63\n",
      "68\n",
      "51\n",
      "85\n",
      "62\n",
      "80\n",
      "55\n",
      "85\n",
      "45\n",
      "85\n",
      "34\n",
      "85\n",
      "39\n",
      "68\n",
      "56\n",
      "80\n",
      "38\n",
      "82\n",
      "47\n",
      "81\n",
      "33\n",
      "88\n",
      "14\n",
      "68\n",
      "22\n",
      "85\n",
      "42\n",
      "87\n",
      "23\n",
      "71\n",
      "23\n",
      "80\n",
      "62\n",
      "89\n",
      "64\n",
      "97\n",
      "39\n",
      "94\n",
      "24\n",
      "69\n",
      "14\n",
      "90\n",
      "56\n",
      "91\n",
      "21\n",
      "92\n",
      "28\n",
      "88\n",
      "26\n",
      "68\n",
      "14\n",
      "85\n",
      "45\n",
      "88\n",
      "42\n",
      "92\n",
      "23\n",
      "97\n",
      "61\n",
      "82\n",
      "38\n",
      "80\n",
      "60\n",
      "74\n",
      "47\n",
      "78\n",
      "62\n",
      "71\n",
      "61\n",
      "79\n",
      "62\n",
      "97\n",
      "37\n",
      "87\n",
      "44\n",
      "95\n",
      "56\n",
      "92\n",
      "50\n",
      "77\n",
      "36\n",
      "91\n",
      "22\n",
      "72\n",
      "18\n",
      "66\n",
      "63\n",
      "89\n",
      "39\n",
      "92\n",
      "19\n",
      "98\n",
      "15\n",
      "98\n",
      "45\n",
      "89\n",
      "64\n",
      "72\n",
      "62\n",
      "78\n",
      "41\n",
      "82\n",
      "61\n",
      "87\n",
      "30\n",
      "90\n",
      "23\n",
      "82\n",
      "52\n",
      "96\n",
      "59\n",
      "74\n",
      "27\n",
      "77\n",
      "21\n",
      "90\n",
      "18\n",
      "82\n",
      "42\n",
      "65\n",
      "29\n",
      "82\n",
      "14\n",
      "99\n",
      "14\n",
      "69\n",
      "34\n",
      "70\n",
      "40\n",
      "91\n",
      "51\n",
      "99\n",
      "15\n",
      "91\n",
      "45\n",
      "94\n",
      "14\n",
      "92\n",
      "53\n",
      "91\n",
      "18\n",
      "91\n",
      "15\n",
      "75\n",
      "41\n",
      "85\n",
      "47\n",
      "88\n",
      "60\n",
      "65\n",
      "30\n",
      "67\n",
      "38\n",
      "100\n",
      "21\n",
      "66\n",
      "56\n",
      "66\n",
      "13\n",
      "72\n",
      "33\n",
      "97\n",
      "55\n",
      "65\n",
      "52\n",
      "72\n",
      "32\n",
      "70\n",
      "44\n",
      "100\n",
      "15\n",
      "77\n",
      "32\n",
      "100\n",
      "64\n",
      "76\n",
      "61\n",
      "81\n",
      "19\n",
      "95\n",
      "34\n",
      "83\n",
      "32\n",
      "90\n",
      "50\n",
      "90\n",
      "25\n",
      "80\n",
      "22\n",
      "99\n",
      "48\n",
      "82\n",
      "37\n",
      "71\n",
      "43\n",
      "77\n",
      "21\n",
      "68\n",
      "55\n",
      "85\n",
      "43\n",
      "66\n",
      "19\n",
      "99\n",
      "63\n",
      "88\n",
      "39\n",
      "86\n",
      "16\n",
      "81\n",
      "32\n",
      "65\n",
      "48\n",
      "84\n",
      "51\n",
      "83\n",
      "62\n",
      "77\n",
      "46\n",
      "65\n",
      "63\n",
      "96\n",
      "53\n",
      "69\n",
      "50\n",
      "95\n",
      "54\n",
      "66\n",
      "14\n",
      "95\n",
      "32\n",
      "77\n",
      "20\n",
      "75\n",
      "22\n",
      "75\n",
      "56\n",
      "90\n",
      "64\n",
      "87\n",
      "34\n",
      "87\n",
      "45\n",
      "88\n",
      "35\n",
      "75\n",
      "40\n",
      "77\n",
      "23\n",
      "82\n",
      "41\n",
      "99\n",
      "45\n",
      "84\n",
      "46\n",
      "78\n",
      "41\n",
      "68\n",
      "55\n",
      "84\n",
      "42\n",
      "89\n",
      "36\n",
      "84\n",
      "56\n",
      "83\n",
      "52\n",
      "65\n",
      "20\n",
      "91\n",
      "52\n",
      "81\n",
      "61\n",
      "87\n",
      "59\n",
      "100\n",
      "56\n",
      "99\n",
      "35\n",
      "65\n",
      "52\n",
      "71\n",
      "64\n",
      "84\n",
      "63\n",
      "76\n",
      "19\n",
      "79\n",
      "21\n",
      "78\n",
      "15\n",
      "79\n",
      "50\n",
      "83\n",
      "23\n",
      "91\n",
      "27\n",
      "97\n",
      "16\n",
      "80\n",
      "13\n",
      "90\n",
      "35\n",
      "84\n",
      "40\n",
      "76\n",
      "26\n",
      "76\n",
      "50\n",
      "69\n",
      "47\n",
      "65\n",
      "27\n",
      "89\n",
      "38\n",
      "93\n",
      "58\n",
      "94\n",
      "16\n",
      "79\n",
      "43\n",
      "93\n",
      "45\n",
      "86\n",
      "59\n",
      "83\n",
      "61\n",
      "66\n",
      "39\n",
      "70\n",
      "51\n",
      "68\n",
      "22\n",
      "98\n",
      "28\n",
      "96\n",
      "23\n",
      "97\n",
      "33\n",
      "75\n",
      "54\n",
      "83\n",
      "29\n",
      "98\n",
      "59\n",
      "81\n",
      "43\n",
      "92\n",
      "43\n",
      "71\n",
      "39\n",
      "67\n",
      "27\n",
      "70\n",
      "29\n",
      "84\n",
      "16\n",
      "75\n",
      "58\n",
      "91\n",
      "17\n",
      "98\n",
      "33\n",
      "80\n",
      "13\n",
      "76\n",
      "47\n",
      "76\n",
      "20\n",
      "84\n",
      "33\n",
      "72\n",
      "22\n",
      "83\n",
      "15\n",
      "97\n",
      "16\n",
      "66\n",
      "37\n",
      "95\n",
      "44\n",
      "69\n",
      "13\n",
      "90\n",
      "63\n",
      "77\n",
      "20\n",
      "100\n",
      "44\n",
      "75\n",
      "25\n",
      "86\n",
      "45\n",
      "91\n",
      "29\n",
      "95\n",
      "47\n",
      "73\n",
      "43\n",
      "79\n",
      "57\n",
      "75\n",
      "57\n",
      "95\n",
      "54\n",
      "82\n",
      "21\n",
      "98\n",
      "17\n",
      "73\n",
      "39\n",
      "92\n",
      "54\n",
      "75\n",
      "54\n",
      "89\n",
      "40\n",
      "88\n",
      "29\n",
      "75\n",
      "32\n",
      "77\n",
      "62\n",
      "83\n",
      "56\n",
      "82\n",
      "57\n",
      "95\n",
      "54\n",
      "69\n",
      "35\n",
      "72\n",
      "37\n",
      "69\n",
      "56\n",
      "97\n",
      "54\n",
      "78\n",
      "52\n",
      "100\n",
      "31\n",
      "84\n",
      "29\n",
      "93\n",
      "63\n",
      "91\n",
      "58\n",
      "67\n",
      "63\n",
      "68\n",
      "60\n",
      "88\n",
      "48\n",
      "66\n",
      "60\n",
      "70\n",
      "31\n",
      "100\n",
      "25\n",
      "72\n",
      "56\n",
      "81\n",
      "36\n",
      "65\n",
      "35\n",
      "94\n",
      "57\n",
      "74\n",
      "59\n",
      "69\n",
      "30\n",
      "83\n",
      "20\n",
      "72\n",
      "21\n",
      "90\n",
      "15\n",
      "91\n",
      "40\n",
      "94\n",
      "14\n",
      "97\n",
      "34\n",
      "100\n",
      "36\n",
      "79\n",
      "21\n",
      "89\n",
      "57\n",
      "88\n",
      "44\n",
      "77\n",
      "58\n",
      "88\n",
      "55\n",
      "70\n",
      "50\n",
      "72\n",
      "53\n",
      "78\n",
      "51\n",
      "81\n",
      "14\n",
      "91\n",
      "49\n",
      "74\n",
      "39\n",
      "97\n",
      "32\n",
      "93\n",
      "57\n",
      "92\n",
      "61\n",
      "79\n",
      "54\n",
      "76\n",
      "24\n",
      "90\n",
      "14\n",
      "70\n",
      "19\n",
      "78\n",
      "54\n",
      "74\n",
      "20\n",
      "76\n",
      "29\n",
      "100\n",
      "53\n",
      "91\n",
      "26\n",
      "98\n",
      "16\n",
      "97\n",
      "47\n",
      "69\n",
      "47\n",
      "79\n",
      "60\n",
      "88\n",
      "27\n",
      "99\n",
      "44\n",
      "89\n",
      "45\n",
      "85\n",
      "61\n",
      "95\n",
      "45\n",
      "73\n",
      "16\n",
      "94\n",
      "38\n",
      "78\n",
      "58\n",
      "73\n",
      "15\n",
      "88\n",
      "34\n",
      "93\n",
      "44\n",
      "93\n",
      "47\n",
      "67\n",
      "62\n",
      "75\n",
      "39\n",
      "84\n",
      "21\n",
      "75\n",
      "56\n",
      "95\n",
      "27\n",
      "95\n",
      "54\n",
      "84\n",
      "35\n",
      "95\n",
      "22\n",
      "99\n",
      "53\n",
      "67\n",
      "56\n",
      "77\n",
      "24\n",
      "81\n",
      "29\n",
      "72\n",
      "14\n",
      "87\n",
      "36\n",
      "77\n",
      "38\n",
      "84\n",
      "57\n",
      "65\n",
      "45\n",
      "71\n",
      "45\n",
      "79\n",
      "28\n",
      "97\n",
      "15\n",
      "95\n",
      "53\n",
      "80\n",
      "46\n",
      "79\n",
      "45\n",
      "85\n",
      "56\n",
      "90\n",
      "57\n",
      "81\n",
      "55\n",
      "72\n",
      "64\n",
      "70\n",
      "22\n",
      "100\n",
      "59\n",
      "94\n",
      "41\n",
      "75\n",
      "61\n",
      "91\n",
      "25\n",
      "83\n",
      "45\n",
      "88\n",
      "27\n",
      "86\n",
      "43\n",
      "84\n",
      "57\n",
      "71\n",
      "26\n",
      "69\n",
      "54\n",
      "93\n",
      "33\n",
      "93\n",
      "58\n",
      "92\n",
      "56\n",
      "90\n",
      "36\n",
      "79\n",
      "16\n",
      "73\n",
      "23\n",
      "74\n",
      "40\n",
      "73\n",
      "49\n",
      "81\n",
      "53\n",
      "97\n",
      "21\n",
      "90\n",
      "13\n",
      "75\n",
      "47\n",
      "86\n",
      "20\n",
      "97\n",
      "59\n",
      "80\n",
      "48\n",
      "90\n",
      "59\n",
      "77\n",
      "19\n",
      "80\n",
      "56\n",
      "88\n",
      "34\n",
      "65\n",
      "37\n",
      "73\n",
      "28\n",
      "95\n",
      "46\n",
      "91\n",
      "26\n",
      "91\n",
      "17\n",
      "85\n",
      "53\n",
      "73\n",
      "40\n",
      "96\n",
      "56\n",
      "65\n",
      "62\n",
      "91\n",
      "20\n",
      "78\n",
      "25\n",
      "92\n",
      "39\n",
      "68\n",
      "31\n",
      "65\n",
      "44\n",
      "86\n",
      "14\n",
      "87\n",
      "26\n",
      "78\n",
      "53\n",
      "65\n",
      "54\n",
      "94\n",
      "18\n",
      "88\n",
      "16\n",
      "79\n",
      "24\n",
      "67\n",
      "33\n",
      "93\n",
      "50\n",
      "96\n",
      "55\n",
      "72\n",
      "38\n",
      "91\n",
      "25\n",
      "66\n",
      "32\n",
      "98\n",
      "59\n",
      "85\n",
      "60\n",
      "68\n",
      "27\n",
      "90\n",
      "19\n",
      "73\n",
      "30\n",
      "74\n",
      "52\n",
      "85\n",
      "61\n",
      "96\n",
      "42\n",
      "97\n",
      "63\n",
      "79\n",
      "40\n",
      "72\n",
      "28\n",
      "81\n",
      "63\n",
      "99\n",
      "58\n",
      "68\n",
      "15\n",
      "76\n",
      "51\n",
      "92\n",
      "37\n",
      "76\n",
      "43\n",
      "91\n",
      "35\n",
      "67\n",
      "61\n",
      "71\n",
      "34\n",
      "73\n",
      "48\n",
      "66\n",
      "63\n",
      "97\n",
      "60\n",
      "78\n",
      "21\n",
      "88\n",
      "41\n",
      "83\n",
      "32\n",
      "73\n",
      "62\n",
      "99\n",
      "22\n",
      "65\n",
      "62\n",
      "83\n",
      "42\n",
      "80\n",
      "45\n",
      "79\n",
      "38\n",
      "77\n",
      "32\n",
      "71\n",
      "32\n",
      "95\n",
      "15\n",
      "77\n",
      "64\n",
      "89\n",
      "28\n",
      "79\n",
      "28\n",
      "84\n",
      "57\n",
      "77\n",
      "18\n",
      "89\n",
      "56\n",
      "74\n",
      "18\n",
      "90\n",
      "20\n",
      "99\n",
      "36\n",
      "86\n",
      "47\n",
      "87\n",
      "36\n",
      "78\n",
      "27\n",
      "98\n",
      "21\n",
      "67\n",
      "26\n",
      "69\n",
      "30\n",
      "91\n",
      "39\n",
      "83\n",
      "49\n",
      "92\n",
      "26\n",
      "81\n",
      "29\n",
      "66\n",
      "53\n",
      "71\n",
      "31\n",
      "85\n",
      "24\n",
      "71\n",
      "47\n",
      "65\n",
      "37\n",
      "100\n",
      "34\n",
      "78\n",
      "26\n",
      "75\n",
      "35\n",
      "92\n",
      "19\n",
      "71\n",
      "14\n",
      "66\n",
      "16\n",
      "71\n",
      "48\n",
      "83\n",
      "64\n",
      "91\n",
      "38\n",
      "94\n",
      "62\n",
      "84\n",
      "26\n",
      "86\n",
      "30\n",
      "86\n",
      "64\n",
      "73\n",
      "29\n",
      "70\n",
      "48\n",
      "97\n",
      "29\n",
      "71\n",
      "41\n",
      "95\n",
      "55\n",
      "66\n",
      "41\n",
      "69\n",
      "57\n",
      "83\n",
      "38\n",
      "84\n",
      "27\n",
      "82\n",
      "36\n",
      "94\n",
      "59\n",
      "96\n",
      "27\n",
      "65\n",
      "43\n",
      "72\n",
      "53\n",
      "79\n",
      "15\n",
      "76\n",
      "38\n",
      "94\n",
      "56\n",
      "71\n",
      "46\n",
      "82\n",
      "28\n",
      "82\n",
      "61\n",
      "89\n",
      "13\n",
      "68\n",
      "33\n",
      "73\n",
      "64\n",
      "100\n",
      "33\n",
      "83\n",
      "41\n",
      "88\n",
      "50\n",
      "94\n",
      "35\n",
      "85\n",
      "23\n",
      "70\n",
      "29\n",
      "82\n",
      "50\n",
      "77\n",
      "21\n",
      "93\n",
      "29\n",
      "100\n",
      "23\n",
      "98\n",
      "31\n",
      "96\n",
      "15\n",
      "69\n",
      "15\n",
      "69\n",
      "19\n",
      "75\n",
      "42\n",
      "72\n",
      "23\n",
      "67\n",
      "35\n",
      "77\n",
      "58\n",
      "65\n",
      "16\n",
      "69\n",
      "61\n",
      "97\n",
      "48\n",
      "86\n",
      "15\n",
      "80\n",
      "30\n",
      "94\n",
      "24\n",
      "73\n",
      "35\n",
      "84\n",
      "18\n",
      "82\n",
      "23\n",
      "68\n",
      "36\n",
      "79\n",
      "62\n",
      "77\n",
      "21\n",
      "66\n",
      "47\n",
      "67\n",
      "52\n",
      "65\n",
      "53\n",
      "72\n",
      "58\n",
      "67\n",
      "26\n",
      "84\n",
      "13\n",
      "87\n",
      "27\n",
      "86\n",
      "51\n",
      "88\n",
      "57\n",
      "70\n",
      "39\n",
      "93\n",
      "18\n",
      "91\n",
      "56\n",
      "94\n",
      "17\n",
      "80\n",
      "57\n",
      "87\n",
      "46\n",
      "71\n",
      "54\n",
      "74\n",
      "59\n",
      "93\n",
      "16\n",
      "73\n",
      "61\n",
      "65\n",
      "57\n",
      "93\n",
      "58\n",
      "67\n",
      "56\n",
      "94\n",
      "55\n",
      "99\n",
      "62\n",
      "70\n",
      "51\n",
      "72\n",
      "16\n",
      "73\n",
      "45\n",
      "77\n",
      "47\n",
      "66\n",
      "44\n",
      "99\n",
      "52\n",
      "73\n",
      "56\n",
      "65\n",
      "35\n",
      "98\n",
      "40\n",
      "97\n",
      "32\n",
      "68\n",
      "29\n",
      "94\n",
      "33\n",
      "89\n",
      "24\n",
      "99\n",
      "55\n",
      "70\n",
      "46\n",
      "69\n",
      "60\n",
      "72\n",
      "56\n",
      "84\n",
      "56\n",
      "84\n",
      "31\n",
      "71\n",
      "16\n",
      "97\n",
      "20\n",
      "85\n",
      "27\n",
      "87\n",
      "32\n",
      "78\n",
      "57\n",
      "93\n",
      "46\n",
      "96\n",
      "26\n",
      "79\n",
      "43\n",
      "79\n",
      "39\n",
      "82\n",
      "15\n",
      "71\n",
      "46\n",
      "65\n",
      "57\n",
      "90\n",
      "46\n",
      "72\n",
      "35\n",
      "74\n",
      "47\n",
      "95\n",
      "26\n",
      "85\n",
      "41\n",
      "96\n",
      "58\n",
      "69\n",
      "17\n",
      "88\n",
      "56\n",
      "75\n",
      "55\n",
      "73\n",
      "60\n",
      "67\n",
      "45\n",
      "68\n",
      "29\n",
      "82\n",
      "48\n",
      "89\n",
      "28\n",
      "92\n",
      "24\n",
      "79\n",
      "54\n",
      "95\n",
      "42\n",
      "92\n",
      "18\n",
      "83\n",
      "44\n",
      "72\n",
      "14\n",
      "86\n",
      "28\n",
      "77\n",
      "49\n",
      "100\n",
      "19\n",
      "91\n",
      "51\n",
      "99\n",
      "61\n",
      "66\n",
      "37\n",
      "87\n",
      "58\n",
      "83\n",
      "38\n",
      "65\n",
      "37\n",
      "96\n",
      "14\n",
      "67\n",
      "56\n",
      "99\n",
      "30\n",
      "94\n",
      "45\n",
      "76\n",
      "31\n",
      "70\n",
      "59\n",
      "100\n",
      "58\n",
      "92\n",
      "41\n",
      "72\n",
      "52\n",
      "100\n",
      "63\n",
      "83\n",
      "45\n",
      "99\n",
      "22\n",
      "71\n",
      "54\n",
      "96\n",
      "31\n",
      "67\n",
      "58\n",
      "77\n",
      "44\n",
      "66\n",
      "23\n",
      "87\n",
      "59\n",
      "79\n",
      "35\n",
      "100\n",
      "17\n",
      "65\n",
      "56\n",
      "68\n",
      "39\n",
      "66\n",
      "20\n",
      "82\n",
      "30\n",
      "66\n",
      "29\n",
      "91\n",
      "55\n",
      "85\n",
      "13\n",
      "95\n",
      "62\n",
      "66\n",
      "55\n",
      "65\n",
      "32\n",
      "85\n",
      "59\n",
      "81\n",
      "27\n",
      "95\n",
      "16\n",
      "71\n",
      "40\n",
      "77\n",
      "63\n",
      "79\n",
      "55\n",
      "73\n",
      "54\n",
      "83\n",
      "13\n",
      "88\n",
      "44\n",
      "96\n",
      "30\n",
      "90\n",
      "57\n",
      "85\n",
      "54\n",
      "69\n",
      "25\n",
      "77\n",
      "15\n",
      "74\n",
      "13\n",
      "100\n",
      "14\n",
      "69\n",
      "46\n",
      "86\n",
      "28\n",
      "84\n",
      "61\n",
      "95\n",
      "39\n",
      "85\n",
      "58\n",
      "98\n",
      "19\n",
      "79\n",
      "20\n",
      "69\n",
      "24\n",
      "74\n",
      "14\n",
      "85\n",
      "36\n",
      "67\n",
      "25\n",
      "96\n",
      "26\n",
      "94\n",
      "30\n",
      "90\n",
      "60\n",
      "82\n",
      "27\n",
      "90\n",
      "50\n",
      "66\n",
      "31\n",
      "90\n",
      "61\n",
      "89\n",
      "43\n",
      "68\n",
      "23\n",
      "90\n",
      "61\n",
      "91\n",
      "57\n",
      "65\n",
      "62\n",
      "80\n",
      "32\n",
      "76\n",
      "30\n",
      "73\n",
      "57\n",
      "100\n",
      "27\n",
      "77\n",
      "47\n",
      "93\n",
      "52\n",
      "95\n",
      "16\n",
      "66\n",
      "51\n",
      "78\n",
      "17\n",
      "95\n",
      "59\n",
      "77\n",
      "29\n",
      "67\n",
      "17\n",
      "80\n",
      "57\n",
      "94\n",
      "54\n",
      "90\n",
      "24\n",
      "71\n",
      "45\n",
      "73\n",
      "36\n",
      "68\n",
      "27\n",
      "77\n",
      "19\n",
      "74\n",
      "37\n",
      "82\n",
      "16\n",
      "89\n",
      "48\n",
      "99\n",
      "58\n",
      "78\n",
      "60\n",
      "75\n",
      "25\n",
      "73\n",
      "33\n",
      "91\n",
      "43\n",
      "97\n",
      "15\n",
      "69\n",
      "44\n",
      "94\n",
      "27\n",
      "80\n",
      "52\n",
      "77\n",
      "18\n",
      "87\n",
      "33\n",
      "80\n",
      "14\n",
      "96\n",
      "52\n",
      "69\n",
      "36\n",
      "92\n",
      "52\n",
      "86\n",
      "37\n",
      "72\n",
      "42\n",
      "86\n",
      "37\n",
      "98\n",
      "56\n",
      "95\n",
      "51\n",
      "81\n",
      "37\n",
      "89\n",
      "61\n",
      "71\n",
      "48\n",
      "84\n",
      "62\n",
      "65\n",
      "38\n",
      "69\n",
      "53\n",
      "100\n",
      "21\n",
      "91\n",
      "36\n",
      "73\n",
      "31\n",
      "75\n",
      "51\n",
      "100\n",
      "17\n",
      "66\n",
      "23\n",
      "95\n",
      "47\n",
      "68\n",
      "60\n",
      "95\n",
      "32\n",
      "99\n",
      "39\n",
      "67\n",
      "28\n",
      "100\n",
      "60\n",
      "75\n",
      "22\n",
      "95\n",
      "63\n",
      "68\n",
      "33\n",
      "100\n",
      "21\n",
      "73\n",
      "51\n",
      "84\n",
      "25\n",
      "74\n",
      "19\n",
      "82\n",
      "21\n",
      "82\n",
      "42\n",
      "85\n",
      "52\n",
      "80\n",
      "64\n",
      "74\n",
      "40\n",
      "88\n",
      "61\n",
      "85\n",
      "16\n",
      "78\n",
      "43\n",
      "91\n",
      "31\n",
      "83\n",
      "42\n",
      "99\n",
      "15\n",
      "68\n",
      "62\n",
      "80\n",
      "49\n",
      "73\n",
      "42\n",
      "67\n",
      "33\n",
      "65\n",
      "45\n",
      "87\n",
      "41\n",
      "66\n",
      "55\n",
      "72\n",
      "22\n",
      "69\n",
      "46\n",
      "94\n",
      "45\n",
      "92\n",
      "20\n",
      "70\n",
      "29\n",
      "95\n",
      "34\n",
      "76\n",
      "58\n",
      "82\n",
      "58\n",
      "95\n",
      "32\n",
      "97\n",
      "21\n",
      "67\n",
      "25\n",
      "96\n",
      "58\n",
      "82\n",
      "29\n",
      "92\n",
      "31\n",
      "71\n",
      "64\n",
      "88\n",
      "45\n",
      "94\n",
      "31\n",
      "74\n",
      "28\n",
      "98\n",
      "13\n",
      "87\n",
      "63\n",
      "99\n",
      "48\n",
      "69\n",
      "58\n",
      "71\n",
      "41\n",
      "97\n",
      "33\n",
      "87\n",
      "45\n",
      "75\n",
      "42\n",
      "97\n",
      "41\n",
      "96\n",
      "41\n",
      "97\n",
      "36\n",
      "91\n",
      "37\n",
      "97\n",
      "61\n",
      "92\n",
      "58\n",
      "93\n",
      "32\n",
      "79\n",
      "52\n",
      "72\n",
      "22\n",
      "98\n",
      "41\n",
      "88\n",
      "63\n",
      "71\n",
      "47\n",
      "92\n",
      "44\n",
      "72\n",
      "50\n",
      "70\n",
      "39\n",
      "77\n",
      "20\n",
      "94\n",
      "20\n",
      "71\n",
      "40\n",
      "90\n",
      "59\n",
      "85\n",
      "45\n",
      "90\n",
      "37\n",
      "80\n",
      "16\n",
      "95\n",
      "62\n",
      "65\n",
      "35\n",
      "99\n",
      "59\n",
      "82\n",
      "58\n",
      "71\n",
      "41\n",
      "89\n",
      "36\n",
      "85\n",
      "53\n",
      "84\n",
      "28\n",
      "97\n",
      "42\n",
      "67\n",
      "16\n",
      "97\n",
      "30\n",
      "81\n",
      "57\n",
      "73\n",
      "59\n",
      "97\n",
      "48\n",
      "96\n",
      "44\n",
      "70\n",
      "30\n",
      "74\n",
      "21\n",
      "99\n",
      "19\n",
      "77\n",
      "40\n",
      "89\n",
      "58\n",
      "92\n",
      "21\n",
      "93\n",
      "27\n",
      "81\n",
      "47\n",
      "67\n",
      "33\n",
      "73\n",
      "35\n",
      "90\n",
      "49\n",
      "97\n",
      "38\n",
      "77\n",
      "35\n",
      "84\n",
      "63\n",
      "67\n",
      "17\n",
      "66\n",
      "32\n",
      "93\n",
      "14\n",
      "72\n",
      "43\n",
      "85\n",
      "36\n",
      "87\n",
      "37\n",
      "72\n",
      "17\n",
      "98\n",
      "35\n",
      "84\n",
      "45\n",
      "99\n",
      "27\n",
      "84\n",
      "28\n",
      "92\n",
      "29\n",
      "73\n",
      "37\n",
      "83\n",
      "17\n",
      "66\n",
      "43\n",
      "84\n",
      "54\n",
      "95\n",
      "53\n",
      "80\n",
      "15\n",
      "83\n",
      "15\n",
      "94\n",
      "23\n",
      "86\n",
      "39\n",
      "88\n",
      "42\n",
      "74\n",
      "61\n",
      "100\n",
      "51\n",
      "81\n",
      "63\n",
      "99\n",
      "51\n",
      "99\n",
      "25\n",
      "95\n",
      "34\n",
      "99\n",
      "24\n",
      "75\n",
      "16\n",
      "68\n",
      "59\n",
      "77\n",
      "45\n",
      "77\n",
      "31\n",
      "83\n",
      "22\n",
      "96\n",
      "49\n",
      "74\n",
      "42\n",
      "66\n",
      "50\n",
      "79\n",
      "16\n",
      "71\n",
      "16\n",
      "75\n",
      "16\n",
      "78\n",
      "26\n",
      "90\n",
      "30\n",
      "71\n",
      "29\n",
      "78\n",
      "39\n",
      "87\n",
      "35\n",
      "68\n",
      "39\n",
      "92\n",
      "48\n",
      "65\n",
      "38\n",
      "78\n",
      "50\n",
      "79\n",
      "25\n",
      "99\n",
      "37\n",
      "68\n",
      "53\n",
      "100\n",
      "40\n",
      "85\n",
      "38\n",
      "77\n",
      "47\n",
      "75\n",
      "18\n",
      "84\n",
      "55\n",
      "80\n",
      "61\n",
      "73\n",
      "20\n",
      "98\n",
      "55\n",
      "74\n",
      "62\n",
      "88\n",
      "63\n",
      "88\n",
      "37\n",
      "79\n",
      "54\n",
      "90\n",
      "39\n",
      "81\n",
      "50\n",
      "75\n",
      "57\n",
      "65\n",
      "22\n",
      "69\n",
      "40\n",
      "89\n",
      "27\n",
      "94\n",
      "40\n",
      "86\n",
      "43\n",
      "78\n",
      "30\n",
      "76\n",
      "47\n",
      "92\n",
      "20\n",
      "83\n",
      "42\n",
      "87\n",
      "62\n",
      "67\n",
      "18\n",
      "86\n",
      "21\n",
      "72\n",
      "30\n",
      "68\n",
      "52\n",
      "92\n",
      "39\n",
      "80\n",
      "16\n",
      "85\n",
      "55\n",
      "74\n",
      "42\n",
      "90\n",
      "14\n",
      "67\n",
      "34\n",
      "80\n",
      "24\n",
      "87\n",
      "42\n",
      "65\n",
      "47\n",
      "81\n",
      "52\n",
      "85\n",
      "40\n",
      "69\n",
      "49\n",
      "93\n",
      "55\n",
      "72\n",
      "49\n",
      "89\n",
      "34\n",
      "65\n",
      "47\n",
      "97\n",
      "32\n",
      "95\n",
      "49\n",
      "67\n",
      "25\n",
      "70\n",
      "55\n",
      "75\n",
      "18\n",
      "92\n",
      "21\n",
      "68\n",
      "29\n",
      "81\n",
      "51\n",
      "79\n",
      "44\n",
      "80\n",
      "61\n",
      "94\n",
      "39\n",
      "69\n",
      "55\n",
      "84\n",
      "38\n",
      "84\n",
      "17\n",
      "88\n",
      "49\n",
      "94\n",
      "28\n",
      "85\n",
      "30\n",
      "86\n",
      "32\n",
      "93\n",
      "16\n",
      "75\n",
      "60\n",
      "75\n",
      "43\n",
      "75\n",
      "53\n",
      "93\n",
      "30\n",
      "74\n",
      "51\n",
      "92\n",
      "18\n",
      "69\n",
      "42\n",
      "69\n",
      "37\n",
      "74\n",
      "28\n",
      "99\n",
      "52\n",
      "85\n",
      "51\n",
      "73\n",
      "32\n",
      "66\n",
      "18\n",
      "78\n",
      "49\n",
      "91\n",
      "53\n",
      "78\n",
      "37\n",
      "73\n",
      "14\n",
      "87\n",
      "31\n",
      "66\n",
      "41\n",
      "73\n",
      "26\n",
      "88\n",
      "47\n",
      "85\n",
      "48\n",
      "96\n",
      "13\n",
      "73\n",
      "30\n",
      "73\n",
      "14\n",
      "93\n",
      "16\n",
      "74\n",
      "63\n",
      "84\n",
      "14\n",
      "79\n",
      "57\n",
      "92\n",
      "59\n",
      "86\n",
      "36\n",
      "74\n",
      "20\n",
      "72\n",
      "17\n",
      "69\n",
      "56\n",
      "81\n",
      "45\n",
      "67\n",
      "61\n",
      "99\n",
      "42\n",
      "89\n",
      "49\n",
      "80\n",
      "38\n",
      "98\n",
      "57\n",
      "97\n",
      "58\n",
      "79\n",
      "40\n",
      "95\n",
      "52\n",
      "80\n",
      "57\n",
      "72\n",
      "63\n",
      "66\n",
      "20\n",
      "74\n",
      "40\n",
      "98\n",
      "32\n",
      "89\n",
      "48\n",
      "92\n",
      "49\n",
      "69\n",
      "33\n",
      "83\n",
      "25\n",
      "85\n",
      "40\n",
      "73\n",
      "27\n",
      "65\n",
      "57\n",
      "69\n",
      "42\n",
      "89\n",
      "35\n",
      "67\n",
      "36\n",
      "74\n",
      "13\n",
      "76\n",
      "15\n",
      "78\n",
      "59\n",
      "90\n",
      "54\n",
      "99\n",
      "40\n",
      "92\n",
      "63\n",
      "81\n",
      "28\n",
      "90\n",
      "29\n",
      "73\n",
      "31\n",
      "91\n",
      "30\n",
      "99\n",
      "18\n",
      "71\n",
      "31\n",
      "84\n",
      "53\n",
      "66\n",
      "16\n",
      "80\n",
      "22\n",
      "98\n",
      "46\n",
      "88\n",
      "55\n",
      "74\n",
      "35\n",
      "78\n",
      "34\n",
      "76\n",
      "13\n",
      "81\n",
      "63\n",
      "77\n",
      "45\n",
      "95\n",
      "22\n",
      "83\n",
      "19\n",
      "98\n",
      "64\n",
      "100\n",
      "56\n",
      "94\n",
      "13\n",
      "68\n",
      "58\n",
      "91\n",
      "27\n",
      "94\n",
      "18\n",
      "75\n",
      "24\n",
      "88\n",
      "22\n",
      "65\n",
      "43\n",
      "76\n",
      "36\n",
      "100\n",
      "44\n",
      "91\n",
      "27\n",
      "96\n",
      "56\n",
      "96\n",
      "54\n",
      "78\n",
      "24\n",
      "69\n",
      "23\n",
      "70\n",
      "60\n",
      "88\n",
      "30\n",
      "84\n",
      "42\n",
      "76\n",
      "59\n",
      "87\n",
      "37\n",
      "92\n",
      "27\n",
      "95\n",
      "19\n",
      "70\n",
      "43\n",
      "66\n",
      "52\n",
      "97\n",
      "19\n",
      "65\n",
      "55\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "for i in train_samples:\n",
    "    print(i)\n",
    "#print(len(train_samples))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in train_labels:\n",
    "    print(i)\n",
    "#print(len(train_samples)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the both lists to numpy arrays as for fit function to send\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "#to remove any order of the data sets(arrays) have to shuffle\n",
    "train_samples, train_labels = shuffle(train_samples, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initially the data are in the range from 13 to 100 and have to convert that range to between 0 and 1 ---this is the data\n",
    "preprocessing part\"\"\" \n",
    "#initially have to define the scaler that we want the data set to prescale\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6091954]\n",
      "[0.16091954]\n",
      "[0.90804598]\n",
      "[0.24137931]\n",
      "[0.36781609]\n",
      "[0.34482759]\n",
      "[0.42528736]\n",
      "[0.94252874]\n",
      "[0.64367816]\n",
      "[0.63218391]\n",
      "[0.71264368]\n",
      "[0.77011494]\n",
      "[0.25287356]\n",
      "[0.88505747]\n",
      "[0.18390805]\n",
      "[0.93103448]\n",
      "[0.29885057]\n",
      "[0.18390805]\n",
      "[0.86206897]\n",
      "[0.6091954]\n",
      "[0.74712644]\n",
      "[0.55172414]\n",
      "[0.36781609]\n",
      "[0.51724138]\n",
      "[0.18390805]\n",
      "[0.49425287]\n",
      "[0.09195402]\n",
      "[0.36781609]\n",
      "[0.48275862]\n",
      "[0.36781609]\n",
      "[0.2183908]\n",
      "[0.1954023]\n",
      "[0.06896552]\n",
      "[0.94252874]\n",
      "[0.68965517]\n",
      "[0.71264368]\n",
      "[0.34482759]\n",
      "[0.8045977]\n",
      "[0.7816092]\n",
      "[0.96551724]\n",
      "[0.86206897]\n",
      "[0.05747126]\n",
      "[0.18390805]\n",
      "[0.64367816]\n",
      "[0.91954023]\n",
      "[0.5862069]\n",
      "[0.91954023]\n",
      "[0.72413793]\n",
      "[0.82758621]\n",
      "[1.]\n",
      "[0.52873563]\n",
      "[0.72413793]\n",
      "[0.75862069]\n",
      "[0.96551724]\n",
      "[0.79310345]\n",
      "[0.11494253]\n",
      "[0.66666667]\n",
      "[0.32183908]\n",
      "[0.82758621]\n",
      "[0.64367816]\n",
      "[0.8045977]\n",
      "[0.03448276]\n",
      "[0.49425287]\n",
      "[0.35632184]\n",
      "[0.71264368]\n",
      "[0.34482759]\n",
      "[0.62068966]\n",
      "[0.09195402]\n",
      "[0.73563218]\n",
      "[0.98850575]\n",
      "[0.4137931]\n",
      "[0.29885057]\n",
      "[0.75862069]\n",
      "[0.27586207]\n",
      "[0.81609195]\n",
      "[0.87356322]\n",
      "[0.55172414]\n",
      "[0.47126437]\n",
      "[0.75862069]\n",
      "[0.89655172]\n",
      "[0.81609195]\n",
      "[0.]\n",
      "[0.97701149]\n",
      "[0.91954023]\n",
      "[0.35632184]\n",
      "[0.59770115]\n",
      "[0.73563218]\n",
      "[0.25287356]\n",
      "[0.56321839]\n",
      "[0.22988506]\n",
      "[0.49425287]\n",
      "[0.86206897]\n",
      "[0.09195402]\n",
      "[0.59770115]\n",
      "[0.75862069]\n",
      "[0.48275862]\n",
      "[0.22988506]\n",
      "[0.82758621]\n",
      "[0.89655172]\n",
      "[0.98850575]\n",
      "[0.83908046]\n",
      "[0.26436782]\n",
      "[0.95402299]\n",
      "[0.01149425]\n",
      "[0.77011494]\n",
      "[0.68965517]\n",
      "[0.93103448]\n",
      "[0.31034483]\n",
      "[0.17241379]\n",
      "[0.16091954]\n",
      "[0.05747126]\n",
      "[0.96551724]\n",
      "[0.44827586]\n",
      "[0.28735632]\n",
      "[0.81609195]\n",
      "[0.89655172]\n",
      "[0.33333333]\n",
      "[0.71264368]\n",
      "[0.43678161]\n",
      "[0.63218391]\n",
      "[0.88505747]\n",
      "[0.74712644]\n",
      "[0.01149425]\n",
      "[0.43678161]\n",
      "[0.27586207]\n",
      "[0.83908046]\n",
      "[0.47126437]\n",
      "[0.27586207]\n",
      "[0.17241379]\n",
      "[0.7816092]\n",
      "[0.47126437]\n",
      "[0.03448276]\n",
      "[0.48275862]\n",
      "[0.09195402]\n",
      "[0.86206897]\n",
      "[0.96551724]\n",
      "[0.42528736]\n",
      "[0.73563218]\n",
      "[0.48275862]\n",
      "[0.26436782]\n",
      "[0.62068966]\n",
      "[0.63218391]\n",
      "[0.33333333]\n",
      "[0.64367816]\n",
      "[0.11494253]\n",
      "[0.28735632]\n",
      "[0.40229885]\n",
      "[0.89655172]\n",
      "[0.87356322]\n",
      "[0.96551724]\n",
      "[0.66666667]\n",
      "[0.45977011]\n",
      "[0.8045977]\n",
      "[0.54022989]\n",
      "[0.62068966]\n",
      "[0.33333333]\n",
      "[0.70114943]\n",
      "[0.51724138]\n",
      "[0.20689655]\n",
      "[0.51724138]\n",
      "[0.34482759]\n",
      "[0.66666667]\n",
      "[0.64367816]\n",
      "[0.27586207]\n",
      "[0.67816092]\n",
      "[0.06896552]\n",
      "[0.13793103]\n",
      "[0.25287356]\n",
      "[0.45977011]\n",
      "[0.01149425]\n",
      "[0.6091954]\n",
      "[0.59770115]\n",
      "[0.20689655]\n",
      "[0.52873563]\n",
      "[0.51724138]\n",
      "[0.14942529]\n",
      "[0.70114943]\n",
      "[0.36781609]\n",
      "[0.25287356]\n",
      "[0.66666667]\n",
      "[0.72413793]\n",
      "[0.68965517]\n",
      "[0.74712644]\n",
      "[0.17241379]\n",
      "[0.55172414]\n",
      "[0.49425287]\n",
      "[0.54022989]\n",
      "[0.79310345]\n",
      "[0.64367816]\n",
      "[0.10344828]\n",
      "[0.1954023]\n",
      "[0.27586207]\n",
      "[0.81609195]\n",
      "[0.01149425]\n",
      "[0.05747126]\n",
      "[0.89655172]\n",
      "[0.22988506]\n",
      "[0.89655172]\n",
      "[0.14942529]\n",
      "[0.82758621]\n",
      "[0.42528736]\n",
      "[0.67816092]\n",
      "[0.47126437]\n",
      "[0.72413793]\n",
      "[0.4137931]\n",
      "[0.88505747]\n",
      "[0.32183908]\n",
      "[0.89655172]\n",
      "[0.85057471]\n",
      "[0.48275862]\n",
      "[0.87356322]\n",
      "[0.93103448]\n",
      "[0.42528736]\n",
      "[0.79310345]\n",
      "[0.94252874]\n",
      "[0.03448276]\n",
      "[0.49425287]\n",
      "[0.67816092]\n",
      "[0.28735632]\n",
      "[0.57471264]\n",
      "[0.87356322]\n",
      "[0.59770115]\n",
      "[0.26436782]\n",
      "[0.71264368]\n",
      "[0.34482759]\n",
      "[0.27586207]\n",
      "[0.66666667]\n",
      "[0.7816092]\n",
      "[0.98850575]\n",
      "[0.09195402]\n",
      "[0.66666667]\n",
      "[0.34482759]\n",
      "[0.71264368]\n",
      "[0.10344828]\n",
      "[0.94252874]\n",
      "[0.71264368]\n",
      "[0.85057471]\n",
      "[0.68965517]\n",
      "[0.90804598]\n",
      "[0.82758621]\n",
      "[0.97701149]\n",
      "[0.25287356]\n",
      "[0.22988506]\n",
      "[0.35632184]\n",
      "[0.97701149]\n",
      "[0.81609195]\n",
      "[0.13793103]\n",
      "[0.87356322]\n",
      "[0.8045977]\n",
      "[0.16091954]\n",
      "[0.74712644]\n",
      "[0.24137931]\n",
      "[0.13793103]\n",
      "[0.18390805]\n",
      "[0.47126437]\n",
      "[0.20689655]\n",
      "[0.73563218]\n",
      "[0.81609195]\n",
      "[0.90804598]\n",
      "[0.09195402]\n",
      "[0.72413793]\n",
      "[0.27586207]\n",
      "[0.6091954]\n",
      "[0.56321839]\n",
      "[0.71264368]\n",
      "[0.20689655]\n",
      "[0.10344828]\n",
      "[0.5862069]\n",
      "[0.44827586]\n",
      "[0.94252874]\n",
      "[0.1954023]\n",
      "[0.87356322]\n",
      "[0.56321839]\n",
      "[0.47126437]\n",
      "[0.28735632]\n",
      "[0.68965517]\n",
      "[0.24137931]\n",
      "[0.98850575]\n",
      "[0.97701149]\n",
      "[0.29885057]\n",
      "[0.66666667]\n",
      "[0.75862069]\n",
      "[0.03448276]\n",
      "[0.01149425]\n",
      "[0.01149425]\n",
      "[0.77011494]\n",
      "[0.62068966]\n",
      "[0.6091954]\n",
      "[0.32183908]\n",
      "[0.68965517]\n",
      "[0.88505747]\n",
      "[0.28735632]\n",
      "[0.77011494]\n",
      "[0.54022989]\n",
      "[0.59770115]\n",
      "[0.49425287]\n",
      "[0.91954023]\n",
      "[0.2183908]\n",
      "[0.18390805]\n",
      "[0.3908046]\n",
      "[0.67816092]\n",
      "[0.01149425]\n",
      "[0.49425287]\n",
      "[0.33333333]\n",
      "[0.87356322]\n",
      "[0.63218391]\n",
      "[0.48275862]\n",
      "[0.98850575]\n",
      "[0.02298851]\n",
      "[0.49425287]\n",
      "[0.97701149]\n",
      "[0.57471264]\n",
      "[0.]\n",
      "[0.74712644]\n",
      "[0.89655172]\n",
      "[0.97701149]\n",
      "[0.96551724]\n",
      "[0.36781609]\n",
      "[0.32183908]\n",
      "[0.33333333]\n",
      "[0.97701149]\n",
      "[0.01149425]\n",
      "[0.52873563]\n",
      "[0.45977011]\n",
      "[0.40229885]\n",
      "[0.50574713]\n",
      "[0.24137931]\n",
      "[0.31034483]\n",
      "[0.17241379]\n",
      "[0.06896552]\n",
      "[0.08045977]\n",
      "[0.68965517]\n",
      "[0.25287356]\n",
      "[0.]\n",
      "[0.59770115]\n",
      "[0.73563218]\n",
      "[0.20689655]\n",
      "[0.89655172]\n",
      "[0.18390805]\n",
      "[0.03448276]\n",
      "[0.01149425]\n",
      "[0.90804598]\n",
      "[0.96551724]\n",
      "[0.64367816]\n",
      "[0.81609195]\n",
      "[0.16091954]\n",
      "[0.88505747]\n",
      "[0.27586207]\n",
      "[0.29885057]\n",
      "[0.4137931]\n",
      "[0.67816092]\n",
      "[0.55172414]\n",
      "[0.8045977]\n",
      "[0.59770115]\n",
      "[0.98850575]\n",
      "[0.98850575]\n",
      "[0.62068966]\n",
      "[0.70114943]\n",
      "[0.83908046]\n",
      "[0.33333333]\n",
      "[0.79310345]\n",
      "[0.12643678]\n",
      "[0.43678161]\n",
      "[0.22988506]\n",
      "[0.29885057]\n",
      "[0.71264368]\n",
      "[0.95402299]\n",
      "[0.90804598]\n",
      "[0.64367816]\n",
      "[0.97701149]\n",
      "[0.08045977]\n",
      "[0.59770115]\n",
      "[0.10344828]\n",
      "[0.43678161]\n",
      "[0.6091954]\n",
      "[0.18390805]\n",
      "[0.49425287]\n",
      "[0.71264368]\n",
      "[0.65517241]\n",
      "[0.90804598]\n",
      "[1.]\n",
      "[0.36781609]\n",
      "[0.03448276]\n",
      "[0.17241379]\n",
      "[0.93103448]\n",
      "[0.17241379]\n",
      "[0.09195402]\n",
      "[0.6091954]\n",
      "[0.02298851]\n",
      "[0.35632184]\n",
      "[0.75862069]\n",
      "[1.]\n",
      "[0.77011494]\n",
      "[0.]\n",
      "[0.36781609]\n",
      "[0.44827586]\n",
      "[0.01149425]\n",
      "[0.43678161]\n",
      "[0.22988506]\n",
      "[0.12643678]\n",
      "[0.11494253]\n",
      "[0.14942529]\n",
      "[0.26436782]\n",
      "[0.83908046]\n",
      "[0.74712644]\n",
      "[0.32183908]\n",
      "[0.74712644]\n",
      "[0.08045977]\n",
      "[0.31034483]\n",
      "[0.29885057]\n",
      "[0.16091954]\n",
      "[0.1954023]\n",
      "[0.75862069]\n",
      "[0.05747126]\n",
      "[0.79310345]\n",
      "[0.95402299]\n",
      "[0.94252874]\n",
      "[0.10344828]\n",
      "[0.09195402]\n",
      "[0.13793103]\n",
      "[0.24137931]\n",
      "[0.68965517]\n",
      "[0.51724138]\n",
      "[0.67816092]\n",
      "[0.73563218]\n",
      "[0.36781609]\n",
      "[0.06896552]\n",
      "[0.70114943]\n",
      "[0.18390805]\n",
      "[0.36781609]\n",
      "[0.68965517]\n",
      "[0.26436782]\n",
      "[0.14942529]\n",
      "[0.18390805]\n",
      "[0.7816092]\n",
      "[0.14942529]\n",
      "[0.68965517]\n",
      "[0.50574713]\n",
      "[0.66666667]\n",
      "[0.95402299]\n",
      "[0.09195402]\n",
      "[0.2183908]\n",
      "[0.65517241]\n",
      "[0.98850575]\n",
      "[0.86206897]\n",
      "[0.44827586]\n",
      "[0.55172414]\n",
      "[0.74712644]\n",
      "[0.42528736]\n",
      "[0.7816092]\n",
      "[0.6091954]\n",
      "[0.5862069]\n",
      "[0.]\n",
      "[0.62068966]\n",
      "[0.79310345]\n",
      "[0.71264368]\n",
      "[0.24137931]\n",
      "[0.74712644]\n",
      "[0.72413793]\n",
      "[0.63218391]\n",
      "[0.33333333]\n",
      "[0.06896552]\n",
      "[0.82758621]\n",
      "[0.67816092]\n",
      "[0.89655172]\n",
      "[0.55172414]\n",
      "[0.89655172]\n",
      "[0.94252874]\n",
      "[0.47126437]\n",
      "[0.85057471]\n",
      "[0.6091954]\n",
      "[0.63218391]\n",
      "[0.26436782]\n",
      "[0.17241379]\n",
      "[0.45977011]\n",
      "[0.93103448]\n",
      "[0.62068966]\n",
      "[0.83908046]\n",
      "[0.59770115]\n",
      "[0.83908046]\n",
      "[0.24137931]\n",
      "[0.12643678]\n",
      "[0.02298851]\n",
      "[0.93103448]\n",
      "[0.1954023]\n",
      "[0.94252874]\n",
      "[0.29885057]\n",
      "[0.52873563]\n",
      "[0.81609195]\n",
      "[0.63218391]\n",
      "[0.25287356]\n",
      "[0.10344828]\n",
      "[0.03448276]\n",
      "[0.94252874]\n",
      "[0.31034483]\n",
      "[0.6091954]\n",
      "[0.16091954]\n",
      "[0.57471264]\n",
      "[0.7816092]\n",
      "[0.05747126]\n",
      "[0.59770115]\n",
      "[0.05747126]\n",
      "[0.77011494]\n",
      "[0.6091954]\n",
      "[0.13793103]\n",
      "[0.90804598]\n",
      "[0.49425287]\n",
      "[0.56321839]\n",
      "[0.66666667]\n",
      "[0.51724138]\n",
      "[0.05747126]\n",
      "[0.34482759]\n",
      "[0.10344828]\n",
      "[0.59770115]\n",
      "[0.75862069]\n",
      "[0.89655172]\n",
      "[0.96551724]\n",
      "[0.64367816]\n",
      "[0.3908046]\n",
      "[0.2183908]\n",
      "[0.40229885]\n",
      "[0.97701149]\n",
      "[0.95402299]\n",
      "[0.11494253]\n",
      "[0.81609195]\n",
      "[0.02298851]\n",
      "[0.96551724]\n",
      "[0.83908046]\n",
      "[0.63218391]\n",
      "[0.86206897]\n",
      "[0.96551724]\n",
      "[0.25287356]\n",
      "[0.6091954]\n",
      "[0.57471264]\n",
      "[0.70114943]\n",
      "[0.70114943]\n",
      "[0.06896552]\n",
      "[0.73563218]\n",
      "[0.91954023]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.77011494]\n",
      "[0.43678161]\n",
      "[0.2183908]\n",
      "[0.70114943]\n",
      "[0.98850575]\n",
      "[0.97701149]\n",
      "[0.27586207]\n",
      "[0.1954023]\n",
      "[0.65517241]\n",
      "[0.90804598]\n",
      "[0.45977011]\n",
      "[0.42528736]\n",
      "[0.87356322]\n",
      "[0.94252874]\n",
      "[0.74712644]\n",
      "[0.94252874]\n",
      "[0.96551724]\n",
      "[0.1954023]\n",
      "[0.37931034]\n",
      "[0.81609195]\n",
      "[0.42528736]\n",
      "[0.18390805]\n",
      "[0.]\n",
      "[0.97701149]\n",
      "[0.05747126]\n",
      "[0.13793103]\n",
      "[0.86206897]\n",
      "[0.62068966]\n",
      "[0.50574713]\n",
      "[0.68965517]\n",
      "[0.90804598]\n",
      "[0.5862069]\n",
      "[0.73563218]\n",
      "[0.48275862]\n",
      "[0.36781609]\n",
      "[0.64367816]\n",
      "[0.48275862]\n",
      "[0.65517241]\n",
      "[1.]\n",
      "[0.6091954]\n",
      "[0.08045977]\n",
      "[0.85057471]\n",
      "[0.42528736]\n",
      "[0.1954023]\n",
      "[0.98850575]\n",
      "[0.98850575]\n",
      "[0.27586207]\n",
      "[0.5862069]\n",
      "[0.29885057]\n",
      "[0.65517241]\n",
      "[0.90804598]\n",
      "[0.59770115]\n",
      "[0.02298851]\n",
      "[0.88505747]\n",
      "[0.8045977]\n",
      "[0.03448276]\n",
      "[0.02298851]\n",
      "[0.77011494]\n",
      "[0.66666667]\n",
      "[0.66666667]\n",
      "[0.71264368]\n",
      "[0.89655172]\n",
      "[0.44827586]\n",
      "[0.27586207]\n",
      "[0.51724138]\n",
      "[0.36781609]\n",
      "[0.98850575]\n",
      "[0.87356322]\n",
      "[0.7816092]\n",
      "[0.17241379]\n",
      "[0.71264368]\n",
      "[0.8045977]\n",
      "[0.63218391]\n",
      "[0.4137931]\n",
      "[0.82758621]\n",
      "[0.24137931]\n",
      "[0.42528736]\n",
      "[0.67816092]\n",
      "[0.67816092]\n",
      "[0.49425287]\n",
      "[0.71264368]\n",
      "[0.]\n",
      "[0.97701149]\n",
      "[0.48275862]\n",
      "[0.79310345]\n",
      "[0.86206897]\n",
      "[1.]\n",
      "[0.93103448]\n",
      "[0.34482759]\n",
      "[0.49425287]\n",
      "[0.77011494]\n",
      "[0.68965517]\n",
      "[0.7816092]\n",
      "[0.85057471]\n",
      "[0.86206897]\n",
      "[0.94252874]\n",
      "[0.77011494]\n",
      "[0.33333333]\n",
      "[0.8045977]\n",
      "[0.55172414]\n",
      "[1.]\n",
      "[0.22988506]\n",
      "[0.48275862]\n",
      "[0.73563218]\n",
      "[0.42528736]\n",
      "[0.68965517]\n",
      "[0.86206897]\n",
      "[0.43678161]\n",
      "[0.63218391]\n",
      "[0.81609195]\n",
      "[0.33333333]\n",
      "[0.47126437]\n",
      "[0.96551724]\n",
      "[0.36781609]\n",
      "[0.7816092]\n",
      "[0.64367816]\n",
      "[0.82758621]\n",
      "[0.05747126]\n",
      "[0.49425287]\n",
      "[0.48275862]\n",
      "[0.44827586]\n",
      "[0.73563218]\n",
      "[0.45977011]\n",
      "[0.05747126]\n",
      "[0.64367816]\n",
      "[0.79310345]\n",
      "[0.73563218]\n",
      "[0.67816092]\n",
      "[0.20689655]\n",
      "[1.]\n",
      "[0.4137931]\n",
      "[0.49425287]\n",
      "[0.33333333]\n",
      "[0.81609195]\n",
      "[0.8045977]\n",
      "[0.91954023]\n",
      "[0.5862069]\n",
      "[0.57471264]\n",
      "[0.03448276]\n",
      "[0.03448276]\n",
      "[0.35632184]\n",
      "[0.51724138]\n",
      "[0.03448276]\n",
      "[0.93103448]\n",
      "[0.35632184]\n",
      "[0.10344828]\n",
      "[0.83908046]\n",
      "[0.8045977]\n",
      "[0.6091954]\n",
      "[0.48275862]\n",
      "[0.71264368]\n",
      "[0.02298851]\n",
      "[0.64367816]\n",
      "[0.35632184]\n",
      "[0.36781609]\n",
      "[0.70114943]\n",
      "[0.02298851]\n",
      "[0.73563218]\n",
      "[0.2183908]\n",
      "[0.57471264]\n",
      "[0.88505747]\n",
      "[0.64367816]\n",
      "[0.88505747]\n",
      "[0.87356322]\n",
      "[0.54022989]\n",
      "[0.89655172]\n",
      "[0.67816092]\n",
      "[0.98850575]\n",
      "[0.77011494]\n",
      "[0.77011494]\n",
      "[0.88505747]\n",
      "[0.95402299]\n",
      "[0.97701149]\n",
      "[0.40229885]\n",
      "[0.13793103]\n",
      "[0.86206897]\n",
      "[0.73563218]\n",
      "[0.02298851]\n",
      "[0.56321839]\n",
      "[0.83908046]\n",
      "[0.79310345]\n",
      "[0.50574713]\n",
      "[0.49425287]\n",
      "[0.98850575]\n",
      "[0.73563218]\n",
      "[0.95402299]\n",
      "[0.95402299]\n",
      "[0.47126437]\n",
      "[0.36781609]\n",
      "[0.09195402]\n",
      "[0.87356322]\n",
      "[0.73563218]\n",
      "[0.27586207]\n",
      "[0.37931034]\n",
      "[0.79310345]\n",
      "[0.59770115]\n",
      "[0.17241379]\n",
      "[0.68965517]\n",
      "[0.34482759]\n",
      "[0.47126437]\n",
      "[0.36781609]\n",
      "[0.67816092]\n",
      "[0.7816092]\n",
      "[0.87356322]\n",
      "[0.81609195]\n",
      "[0.86206897]\n",
      "[0.70114943]\n",
      "[0.74712644]\n",
      "[0.75862069]\n",
      "[0.37931034]\n",
      "[0.83908046]\n",
      "[0.67816092]\n",
      "[0.14942529]\n",
      "[0.36781609]\n",
      "[0.98850575]\n",
      "[0.49425287]\n",
      "[0.82758621]\n",
      "[0.44827586]\n",
      "[0.91954023]\n",
      "[0.34482759]\n",
      "[0.93103448]\n",
      "[0.94252874]\n",
      "[0.64367816]\n",
      "[0.91954023]\n",
      "[0.28735632]\n",
      "[0.83908046]\n",
      "[0.2183908]\n",
      "[0.02298851]\n",
      "[0.20689655]\n",
      "[0.86206897]\n",
      "[0.94252874]\n",
      "[0.81609195]\n",
      "[0.4137931]\n",
      "[0.54022989]\n",
      "[0.28735632]\n",
      "[0.50574713]\n",
      "[0.72413793]\n",
      "[0.89655172]\n",
      "[0.48275862]\n",
      "[0.18390805]\n",
      "[0.26436782]\n",
      "[0.75862069]\n",
      "[0.04597701]\n",
      "[0.71264368]\n",
      "[0.98850575]\n",
      "[0.70114943]\n",
      "[0.81609195]\n",
      "[0.89655172]\n",
      "[0.75862069]\n",
      "[0.75862069]\n",
      "[0.1954023]\n",
      "[0.13793103]\n",
      "[0.97701149]\n",
      "[0.81609195]\n",
      "[0.90804598]\n",
      "[0.05747126]\n",
      "[0.1954023]\n",
      "[0.94252874]\n",
      "[0.06896552]\n",
      "[0.2183908]\n",
      "[0.57471264]\n",
      "[0.55172414]\n",
      "[0.51724138]\n",
      "[0.56321839]\n",
      "[0.43678161]\n",
      "[0.66666667]\n",
      "[0.55172414]\n",
      "[0.72413793]\n",
      "[0.63218391]\n",
      "[0.96551724]\n",
      "[0.25287356]\n",
      "[0.87356322]\n",
      "[0.57471264]\n",
      "[0.16091954]\n",
      "[0.63218391]\n",
      "[0.70114943]\n",
      "[0.44827586]\n",
      "[0.79310345]\n",
      "[0.98850575]\n",
      "[0.8045977]\n",
      "[0.2183908]\n",
      "[0.57471264]\n",
      "[0.04597701]\n",
      "[0.82758621]\n",
      "[0.70114943]\n",
      "[0.16091954]\n",
      "[0.52873563]\n",
      "[0.75862069]\n",
      "[0.88505747]\n",
      "[0.11494253]\n",
      "[0.8045977]\n",
      "[0.62068966]\n",
      "[0.63218391]\n",
      "[0.65517241]\n",
      "[0.11494253]\n",
      "[1.]\n",
      "[0.71264368]\n",
      "[0.73563218]\n",
      "[0.68965517]\n",
      "[0.42528736]\n",
      "[0.67816092]\n",
      "[0.94252874]\n",
      "[0.04597701]\n",
      "[0.86206897]\n",
      "[0.96551724]\n",
      "[0.87356322]\n",
      "[0.50574713]\n",
      "[0.63218391]\n",
      "[0.74712644]\n",
      "[0.36781609]\n",
      "[0.52873563]\n",
      "[0.12643678]\n",
      "[0.57471264]\n",
      "[0.35632184]\n",
      "[0.24137931]\n",
      "[0.01149425]\n",
      "[0.31034483]\n",
      "[0.43678161]\n",
      "[0.18390805]\n",
      "[0.25287356]\n",
      "[0.35632184]\n",
      "[0.1954023]\n",
      "[0.08045977]\n",
      "[0.7816092]\n",
      "[0.10344828]\n",
      "[0.98850575]\n",
      "[0.89655172]\n",
      "[0.8045977]\n",
      "[0.27586207]\n",
      "[0.03448276]\n",
      "[0.29885057]\n",
      "[0.49425287]\n",
      "[0.70114943]\n",
      "[0.44827586]\n",
      "[0.44827586]\n",
      "[0.04597701]\n",
      "[0.91954023]\n",
      "[1.]\n",
      "[0.51724138]\n",
      "[0.79310345]\n",
      "[0.73563218]\n",
      "[0.09195402]\n",
      "[0.56321839]\n",
      "[0.64367816]\n",
      "[0.16091954]\n",
      "[0.59770115]\n",
      "[0.95402299]\n",
      "[0.74712644]\n",
      "[0.14942529]\n",
      "[0.59770115]\n",
      "[0.3908046]\n",
      "[0.68965517]\n",
      "[0.67816092]\n",
      "[0.62068966]\n",
      "[0.75862069]\n",
      "[0.67816092]\n",
      "[0.12643678]\n",
      "[0.86206897]\n",
      "[0.28735632]\n",
      "[0.94252874]\n",
      "[0.31034483]\n",
      "[0.83908046]\n",
      "[0.64367816]\n",
      "[0.74712644]\n",
      "[0.63218391]\n",
      "[0.37931034]\n",
      "[0.28735632]\n",
      "[0.73563218]\n",
      "[0.6091954]\n",
      "[0.81609195]\n",
      "[0.82758621]\n",
      "[0.3908046]\n",
      "[0.68965517]\n",
      "[0.95402299]\n",
      "[0.43678161]\n",
      "[0.90804598]\n",
      "[0.87356322]\n",
      "[0.73563218]\n",
      "[0.2183908]\n",
      "[0.28735632]\n",
      "[0.70114943]\n",
      "[0.32183908]\n",
      "[1.]\n",
      "[0.55172414]\n",
      "[0.55172414]\n",
      "[0.29885057]\n",
      "[0.]\n",
      "[0.16091954]\n",
      "[0.26436782]\n",
      "[1.]\n",
      "[0.96551724]\n",
      "[0.20689655]\n",
      "[1.]\n",
      "[0.62068966]\n",
      "[0.87356322]\n",
      "[0.96551724]\n",
      "[0.91954023]\n",
      "[0.91954023]\n",
      "[0.40229885]\n",
      "[0.90804598]\n",
      "[0.44827586]\n",
      "[0.70114943]\n",
      "[0.56321839]\n",
      "[0.4137931]\n",
      "[0.93103448]\n",
      "[0.77011494]\n",
      "[0.3908046]\n",
      "[0.27586207]\n",
      "[0.03448276]\n",
      "[0.94252874]\n",
      "[0.81609195]\n",
      "[0.03448276]\n",
      "[0.40229885]\n",
      "[0.88505747]\n",
      "[0.7816092]\n",
      "[0.72413793]\n",
      "[0.74712644]\n",
      "[0.20689655]\n",
      "[0.48275862]\n",
      "[0.51724138]\n",
      "[0.73563218]\n",
      "[0.66666667]\n",
      "[0.36781609]\n",
      "[1.]\n",
      "[0.03448276]\n",
      "[0.36781609]\n",
      "[0.3908046]\n",
      "[0.91954023]\n",
      "[0.79310345]\n",
      "[0.67816092]\n",
      "[0.3908046]\n",
      "[0.29885057]\n",
      "[0.11494253]\n",
      "[0.50574713]\n",
      "[0.91954023]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.03448276]\n",
      "[0.7816092]\n",
      "[0.04597701]\n",
      "[0.10344828]\n",
      "[0.33333333]\n",
      "[0.36781609]\n",
      "[0.7816092]\n",
      "[0.31034483]\n",
      "[0.37931034]\n",
      "[0.68965517]\n",
      "[0.88505747]\n",
      "[0.86206897]\n",
      "[0.95402299]\n",
      "[0.02298851]\n",
      "[0.74712644]\n",
      "[0.94252874]\n",
      "[0.28735632]\n",
      "[0.22988506]\n",
      "[0.22988506]\n",
      "[0.31034483]\n",
      "[0.64367816]\n",
      "[0.50574713]\n",
      "[0.1954023]\n",
      "[0.94252874]\n",
      "[0.62068966]\n",
      "[0.75862069]\n",
      "[0.52873563]\n",
      "[0.94252874]\n",
      "[0.94252874]\n",
      "[0.09195402]\n",
      "[0.49425287]\n",
      "[0.81609195]\n",
      "[0.86206897]\n",
      "[0.98850575]\n",
      "[0.13793103]\n",
      "[0.05747126]\n",
      "[0.34482759]\n",
      "[0.93103448]\n",
      "[0.68965517]\n",
      "[0.68965517]\n",
      "[0.13793103]\n",
      "[0.45977011]\n",
      "[0.16091954]\n",
      "[0.2183908]\n",
      "[0.31034483]\n",
      "[0.18390805]\n",
      "[0.31034483]\n",
      "[0.93103448]\n",
      "[0.66666667]\n",
      "[0.35632184]\n",
      "[0.18390805]\n",
      "[0.98850575]\n",
      "[0.57471264]\n",
      "[0.57471264]\n",
      "[0.12643678]\n",
      "[0.11494253]\n",
      "[0.67816092]\n",
      "[0.1954023]\n",
      "[0.85057471]\n",
      "[0.71264368]\n",
      "[0.11494253]\n",
      "[0.34482759]\n",
      "[0.16091954]\n",
      "[0.95402299]\n",
      "[0.62068966]\n",
      "[0.74712644]\n",
      "[0.33333333]\n",
      "[0.93103448]\n",
      "[0.2183908]\n",
      "[0.49425287]\n",
      "[0.65517241]\n",
      "[0.67816092]\n",
      "[0.28735632]\n",
      "[0.14942529]\n",
      "[0.51724138]\n",
      "[0.26436782]\n",
      "[0.88505747]\n",
      "[0.3908046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51724138]\n",
      "[0.02298851]\n",
      "[0.85057471]\n",
      "[0.01149425]\n",
      "[0.47126437]\n",
      "[0.89655172]\n",
      "[0.68965517]\n",
      "[0.7816092]\n",
      "[0.2183908]\n",
      "[0.88505747]\n",
      "[0.95402299]\n",
      "[0.62068966]\n",
      "[0.03448276]\n",
      "[0.50574713]\n",
      "[0.86206897]\n",
      "[0.7816092]\n",
      "[0.11494253]\n",
      "[0.55172414]\n",
      "[0.42528736]\n",
      "[0.29885057]\n",
      "[0.01149425]\n",
      "[0.54022989]\n",
      "[0.27586207]\n",
      "[0.51724138]\n",
      "[0.44827586]\n",
      "[0.75862069]\n",
      "[0.17241379]\n",
      "[0.63218391]\n",
      "[0.64367816]\n",
      "[0.81609195]\n",
      "[0.50574713]\n",
      "[0.5862069]\n",
      "[0.82758621]\n",
      "[0.90804598]\n",
      "[0.74712644]\n",
      "[0.47126437]\n",
      "[0.49425287]\n",
      "[0.63218391]\n",
      "[0.86206897]\n",
      "[0.3908046]\n",
      "[0.5862069]\n",
      "[0.16091954]\n",
      "[0.73563218]\n",
      "[0.64367816]\n",
      "[0.35632184]\n",
      "[0.34482759]\n",
      "[0.02298851]\n",
      "[0.93103448]\n",
      "[0.03448276]\n",
      "[0.34482759]\n",
      "[0.50574713]\n",
      "[0.72413793]\n",
      "[0.16091954]\n",
      "[0.90804598]\n",
      "[0.89655172]\n",
      "[0.83908046]\n",
      "[0.94252874]\n",
      "[0.88505747]\n",
      "[0.1954023]\n",
      "[0.33333333]\n",
      "[0.18390805]\n",
      "[0.04597701]\n",
      "[0.52873563]\n",
      "[0.52873563]\n",
      "[0.36781609]\n",
      "[0.62068966]\n",
      "[0.89655172]\n",
      "[0.32183908]\n",
      "[0.34482759]\n",
      "[0.2183908]\n",
      "[0.97701149]\n",
      "[0.82758621]\n",
      "[0.10344828]\n",
      "[0.57471264]\n",
      "[0.01149425]\n",
      "[0.75862069]\n",
      "[1.]\n",
      "[0.62068966]\n",
      "[0.17241379]\n",
      "[0.66666667]\n",
      "[0.56321839]\n",
      "[0.79310345]\n",
      "[0.89655172]\n",
      "[0.32183908]\n",
      "[0.73563218]\n",
      "[0.4137931]\n",
      "[0.75862069]\n",
      "[0.89655172]\n",
      "[0.5862069]\n",
      "[0.11494253]\n",
      "[0.26436782]\n",
      "[0.91954023]\n",
      "[0.5862069]\n",
      "[0.74712644]\n",
      "[0.71264368]\n",
      "[0.40229885]\n",
      "[0.22988506]\n",
      "[0.86206897]\n",
      "[0.85057471]\n",
      "[0.70114943]\n",
      "[0.62068966]\n",
      "[0.44827586]\n",
      "[0.74712644]\n",
      "[0.10344828]\n",
      "[0.14942529]\n",
      "[0.96551724]\n",
      "[0.24137931]\n",
      "[0.56321839]\n",
      "[0.03448276]\n",
      "[0.09195402]\n",
      "[0.68965517]\n",
      "[0.1954023]\n",
      "[0.62068966]\n",
      "[0.49425287]\n",
      "[0.01149425]\n",
      "[0.75862069]\n",
      "[0.06896552]\n",
      "[0.08045977]\n",
      "[0.68965517]\n",
      "[0.88505747]\n",
      "[0.55172414]\n",
      "[0.70114943]\n",
      "[0.64367816]\n",
      "[0.51724138]\n",
      "[0.82758621]\n",
      "[0.51724138]\n",
      "[0.98850575]\n",
      "[0.22988506]\n",
      "[0.90804598]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.98850575]\n",
      "[0.62068966]\n",
      "[0.08045977]\n",
      "[0.29885057]\n",
      "[0.65517241]\n",
      "[0.81609195]\n",
      "[0.57471264]\n",
      "[0.47126437]\n",
      "[0.62068966]\n",
      "[0.01149425]\n",
      "[0.01149425]\n",
      "[0.63218391]\n",
      "[0.67816092]\n",
      "[0.73563218]\n",
      "[0.16091954]\n",
      "[0.8045977]\n",
      "[0.93103448]\n",
      "[0.90804598]\n",
      "[0.14942529]\n",
      "[0.63218391]\n",
      "[0.3908046]\n",
      "[0.87356322]\n",
      "[0.3908046]\n",
      "[0.89655172]\n",
      "[0.86206897]\n",
      "[0.6091954]\n",
      "[0.66666667]\n",
      "[0.6091954]\n",
      "[0.51724138]\n",
      "[0.77011494]\n",
      "[0.05747126]\n",
      "[0.11494253]\n",
      "[0.88505747]\n",
      "[0.82758621]\n",
      "[0.06896552]\n",
      "[0.18390805]\n",
      "[0.72413793]\n",
      "[0.90804598]\n",
      "[0.8045977]\n",
      "[0.06896552]\n",
      "[0.25287356]\n",
      "[0.08045977]\n",
      "[0.2183908]\n",
      "[0.85057471]\n",
      "[0.59770115]\n",
      "[0.70114943]\n",
      "[0.2183908]\n",
      "[0.59770115]\n",
      "[0.59770115]\n",
      "[0.1954023]\n",
      "[0.71264368]\n",
      "[0.09195402]\n",
      "[0.96551724]\n",
      "[0.44827586]\n",
      "[0.1954023]\n",
      "[0.52873563]\n",
      "[0.98850575]\n",
      "[0.3908046]\n",
      "[0.49425287]\n",
      "[0.50574713]\n",
      "[0.74712644]\n",
      "[0.49425287]\n",
      "[0.64367816]\n",
      "[0.16091954]\n",
      "[0.59770115]\n",
      "[0.05747126]\n",
      "[0.85057471]\n",
      "[0.89655172]\n",
      "[0.85057471]\n",
      "[0.16091954]\n",
      "[0.26436782]\n",
      "[0.64367816]\n",
      "[0.11494253]\n",
      "[0.34482759]\n",
      "[0.67816092]\n",
      "[0.33333333]\n",
      "[0.59770115]\n",
      "[0.28735632]\n",
      "[0.88505747]\n",
      "[0.44827586]\n",
      "[0.82758621]\n",
      "[0.7816092]\n",
      "[0.45977011]\n",
      "[0.17241379]\n",
      "[0.]\n",
      "[0.97701149]\n",
      "[0.98850575]\n",
      "[0.70114943]\n",
      "[0.2183908]\n",
      "[0.08045977]\n",
      "[0.96551724]\n",
      "[0.25287356]\n",
      "[0.63218391]\n",
      "[0.96551724]\n",
      "[0.22988506]\n",
      "[0.94252874]\n",
      "[0.86206897]\n",
      "[0.06896552]\n",
      "[0.71264368]\n",
      "[0.59770115]\n",
      "[0.96551724]\n",
      "[0.10344828]\n",
      "[0.8045977]\n",
      "[0.33333333]\n",
      "[0.67816092]\n",
      "[0.1954023]\n",
      "[0.2183908]\n",
      "[0.59770115]\n",
      "[0.31034483]\n",
      "[0.56321839]\n",
      "[0.94252874]\n",
      "[0.12643678]\n",
      "[0.36781609]\n",
      "[0.7816092]\n",
      "[0.71264368]\n",
      "[0.48275862]\n",
      "[0.59770115]\n",
      "[0.52873563]\n",
      "[0.64367816]\n",
      "[0.79310345]\n",
      "[0.95402299]\n",
      "[0.52873563]\n",
      "[0.2183908]\n",
      "[0.77011494]\n",
      "[0.]\n",
      "[0.98850575]\n",
      "[0.37931034]\n",
      "[0.74712644]\n",
      "[0.66666667]\n",
      "[0.67816092]\n",
      "[0.73563218]\n",
      "[0.79310345]\n",
      "[0.14942529]\n",
      "[0.3908046]\n",
      "[0.94252874]\n",
      "[0.37931034]\n",
      "[0.12643678]\n",
      "[0.89655172]\n",
      "[0.81609195]\n",
      "[0.37931034]\n",
      "[0.82758621]\n",
      "[0.]\n",
      "[0.54022989]\n",
      "[0.77011494]\n",
      "[0.3908046]\n",
      "[0.36781609]\n",
      "[0.71264368]\n",
      "[0.68965517]\n",
      "[0.6091954]\n",
      "[0.51724138]\n",
      "[0.31034483]\n",
      "[0.06896552]\n",
      "[0.3908046]\n",
      "[0.16091954]\n",
      "[0.09195402]\n",
      "[0.90804598]\n",
      "[0.02298851]\n",
      "[0.70114943]\n",
      "[0.33333333]\n",
      "[0.48275862]\n",
      "[0.91954023]\n",
      "[0.40229885]\n",
      "[0.97701149]\n",
      "[0.3908046]\n",
      "[0.63218391]\n",
      "[0.77011494]\n",
      "[1.]\n",
      "[0.91954023]\n",
      "[0.25287356]\n",
      "[0.]\n",
      "[0.57471264]\n",
      "[0.31034483]\n",
      "[0.82758621]\n",
      "[0.01149425]\n",
      "[0.93103448]\n",
      "[0.6091954]\n",
      "[0.09195402]\n",
      "[0.32183908]\n",
      "[0.20689655]\n",
      "[0.6091954]\n",
      "[0.82758621]\n",
      "[0.66666667]\n",
      "[0.67816092]\n",
      "[0.65517241]\n",
      "[0.98850575]\n",
      "[0.49425287]\n",
      "[0.87356322]\n",
      "[0.90804598]\n",
      "[0.79310345]\n",
      "[0.59770115]\n",
      "[0.36781609]\n",
      "[0.52873563]\n",
      "[0.85057471]\n",
      "[0.55172414]\n",
      "[0.67816092]\n",
      "[0.74712644]\n",
      "[0.50574713]\n",
      "[0.05747126]\n",
      "[0.12643678]\n",
      "[0.88505747]\n",
      "[0.82758621]\n",
      "[0.56321839]\n",
      "[0.94252874]\n",
      "[0.90804598]\n",
      "[0.45977011]\n",
      "[0.22988506]\n",
      "[0.01149425]\n",
      "[0.65517241]\n",
      "[0.87356322]\n",
      "[0.16091954]\n",
      "[0.75862069]\n",
      "[0.64367816]\n",
      "[0.89655172]\n",
      "[0.64367816]\n",
      "[0.03448276]\n",
      "[0.1954023]\n",
      "[0.59770115]\n",
      "[0.48275862]\n",
      "[0.54022989]\n",
      "[0.65517241]\n",
      "[0.55172414]\n",
      "[0.56321839]\n",
      "[0.09195402]\n",
      "[0.24137931]\n",
      "[0.47126437]\n",
      "[0.18390805]\n",
      "[0.50574713]\n",
      "[0.45977011]\n",
      "[0.05747126]\n",
      "[0.6091954]\n",
      "[0.36781609]\n",
      "[0.91954023]\n",
      "[0.87356322]\n",
      "[0.25287356]\n",
      "[0.47126437]\n",
      "[1.]\n",
      "[0.93103448]\n",
      "[0.64367816]\n",
      "[0.77011494]\n",
      "[0.63218391]\n",
      "[0.98850575]\n",
      "[0.01149425]\n",
      "[0.87356322]\n",
      "[0.56321839]\n",
      "[0.32183908]\n",
      "[0.96551724]\n",
      "[0.71264368]\n",
      "[0.85057471]\n",
      "[0.06896552]\n",
      "[0.09195402]\n",
      "[0.81609195]\n",
      "[0.81609195]\n",
      "[0.57471264]\n",
      "[0.54022989]\n",
      "[0.13793103]\n",
      "[0.12643678]\n",
      "[0.29885057]\n",
      "[0.49425287]\n",
      "[0.63218391]\n",
      "[0.75862069]\n",
      "[0.37931034]\n",
      "[0.66666667]\n",
      "[0.59770115]\n",
      "[0.10344828]\n",
      "[0.70114943]\n",
      "[0.47126437]\n",
      "[0.4137931]\n",
      "[0.74712644]\n",
      "[0.66666667]\n",
      "[0.77011494]\n",
      "[0.40229885]\n",
      "[0.71264368]\n",
      "[0.82758621]\n",
      "[0.97701149]\n",
      "[0.96551724]\n",
      "[0.79310345]\n",
      "[0.72413793]\n",
      "[0.8045977]\n",
      "[0.72413793]\n",
      "[0.14942529]\n",
      "[0.09195402]\n",
      "[0.89655172]\n",
      "[0.40229885]\n",
      "[0.6091954]\n",
      "[0.33333333]\n",
      "[0.16091954]\n",
      "[0.4137931]\n",
      "[0.8045977]\n",
      "[0.68965517]\n",
      "[0.83908046]\n",
      "[0.02298851]\n",
      "[0.87356322]\n",
      "[0.22988506]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.75862069]\n",
      "[0.49425287]\n",
      "[0.24137931]\n",
      "[0.90804598]\n",
      "[0.27586207]\n",
      "[0.31034483]\n",
      "[0.55172414]\n",
      "[0.18390805]\n",
      "[0.16091954]\n",
      "[0.03448276]\n",
      "[0.93103448]\n",
      "[0.79310345]\n",
      "[0.93103448]\n",
      "[0.68965517]\n",
      "[0.86206897]\n",
      "[0.02298851]\n",
      "[0.73563218]\n",
      "[0.77011494]\n",
      "[1.]\n",
      "[0.82758621]\n",
      "[0.27586207]\n",
      "[0.66666667]\n",
      "[0.90804598]\n",
      "[0.91954023]\n",
      "[0.86206897]\n",
      "[0.51724138]\n",
      "[0.86206897]\n",
      "[0.29885057]\n",
      "[0.63218391]\n",
      "[0.88505747]\n",
      "[0.89655172]\n",
      "[0.68965517]\n",
      "[0.55172414]\n",
      "[0.17241379]\n",
      "[0.72413793]\n",
      "[0.79310345]\n",
      "[0.71264368]\n",
      "[0.50574713]\n",
      "[0.25287356]\n",
      "[0.34482759]\n",
      "[0.93103448]\n",
      "[0.64367816]\n",
      "[0.93103448]\n",
      "[0.88505747]\n",
      "[0.59770115]\n",
      "[0.96551724]\n",
      "[0.24137931]\n",
      "[0.52873563]\n",
      "[0.87356322]\n",
      "[0.82758621]\n",
      "[0.67816092]\n",
      "[0.88505747]\n",
      "[0.33333333]\n",
      "[0.04597701]\n",
      "[0.83908046]\n",
      "[0.89655172]\n",
      "[0.17241379]\n",
      "[0.5862069]\n",
      "[0.49425287]\n",
      "[0.81609195]\n",
      "[0.45977011]\n",
      "[0.26436782]\n",
      "[0.59770115]\n",
      "[0.82758621]\n",
      "[0.33333333]\n",
      "[0.06896552]\n",
      "[0.11494253]\n",
      "[0.51724138]\n",
      "[0.85057471]\n",
      "[0.64367816]\n",
      "[0.6091954]\n",
      "[0.64367816]\n",
      "[0.03448276]\n",
      "[0.8045977]\n",
      "[0.27586207]\n",
      "[0.88505747]\n",
      "[0.82758621]\n",
      "[0.90804598]\n",
      "[0.33333333]\n",
      "[0.22988506]\n",
      "[0.47126437]\n",
      "[0.36781609]\n",
      "[0.62068966]\n",
      "[0.35632184]\n",
      "[0.25287356]\n",
      "[0.79310345]\n",
      "[0.40229885]\n",
      "[0.70114943]\n",
      "[0.95402299]\n",
      "[0.03448276]\n",
      "[0.70114943]\n",
      "[0.02298851]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.2183908]\n",
      "[0.96551724]\n",
      "[0.29885057]\n",
      "[0.96551724]\n",
      "[0.29885057]\n",
      "[0.03448276]\n",
      "[0.96551724]\n",
      "[0.27586207]\n",
      "[0.26436782]\n",
      "[0.1954023]\n",
      "[0.95402299]\n",
      "[0.43678161]\n",
      "[0.01149425]\n",
      "[0.89655172]\n",
      "[0.82758621]\n",
      "[0.8045977]\n",
      "[0.57471264]\n",
      "[0.73563218]\n",
      "[0.3908046]\n",
      "[0.10344828]\n",
      "[0.10344828]\n",
      "[0.85057471]\n",
      "[0.08045977]\n",
      "[0.85057471]\n",
      "[0.42528736]\n",
      "[0.45977011]\n",
      "[0.63218391]\n",
      "[0.31034483]\n",
      "[0.52873563]\n",
      "[0.65517241]\n",
      "[0.47126437]\n",
      "[0.6091954]\n",
      "[0.83908046]\n",
      "[0.88505747]\n",
      "[0.29885057]\n",
      "[0.08045977]\n",
      "[0.13793103]\n",
      "[0.06896552]\n",
      "[0.95402299]\n",
      "[1.]\n",
      "[0.02298851]\n",
      "[0.65517241]\n",
      "[1.]\n",
      "[0.86206897]\n",
      "[0.97701149]\n",
      "[0.40229885]\n",
      "[0.1954023]\n",
      "[0.50574713]\n",
      "[0.27586207]\n",
      "[0.51724138]\n",
      "[0.3908046]\n",
      "[0.82758621]\n",
      "[0.]\n",
      "[0.97701149]\n",
      "[0.32183908]\n",
      "[0.89655172]\n",
      "[0.91954023]\n",
      "[0.86206897]\n",
      "[0.5862069]\n",
      "[0.67816092]\n",
      "[0.68965517]\n",
      "[0.95402299]\n",
      "[0.79310345]\n",
      "[0.04597701]\n",
      "[0.62068966]\n",
      "[0.75862069]\n",
      "[0.75862069]\n",
      "[0.86206897]\n",
      "[0.31034483]\n",
      "[0.71264368]\n",
      "[0.44827586]\n",
      "[0.93103448]\n",
      "[0.89655172]\n",
      "[0.66666667]\n",
      "[0.94252874]\n",
      "[0.12643678]\n",
      "[0.98850575]\n",
      "[0.66666667]\n",
      "[0.25287356]\n",
      "[0.8045977]\n",
      "[0.75862069]\n",
      "[0.7816092]\n",
      "[0.97701149]\n",
      "[0.29885057]\n",
      "[0.73563218]\n",
      "[0.52873563]\n",
      "[0.6091954]\n",
      "[0.55172414]\n",
      "[0.22988506]\n",
      "[0.88505747]\n",
      "[0.65517241]\n",
      "[0.29885057]\n",
      "[0.09195402]\n",
      "[0.66666667]\n",
      "[0.43678161]\n",
      "[0.72413793]\n",
      "[0.67816092]\n",
      "[0.14942529]\n",
      "[0.67816092]\n",
      "[0.35632184]\n",
      "[0.47126437]\n",
      "[0.59770115]\n",
      "[0.93103448]\n",
      "[0.32183908]\n",
      "[0.20689655]\n",
      "[0.6091954]\n",
      "[0.68965517]\n",
      "[0.70114943]\n",
      "[0.29885057]\n",
      "[0.62068966]\n",
      "[0.96551724]\n",
      "[0.89655172]\n",
      "[0.67816092]\n",
      "[0.6091954]\n",
      "[0.44827586]\n",
      "[0.68965517]\n",
      "[0.26436782]\n",
      "[0.82758621]\n",
      "[0.40229885]\n",
      "[0.5862069]\n",
      "[0.27586207]\n",
      "[0.77011494]\n",
      "[1.]\n",
      "[0.28735632]\n",
      "[0.85057471]\n",
      "[0.71264368]\n",
      "[0.08045977]\n",
      "[0.25287356]\n",
      "[0.90804598]\n",
      "[0.85057471]\n",
      "[0.2183908]\n",
      "[0.59770115]\n",
      "[0.08045977]\n",
      "[0.17241379]\n",
      "[0.81609195]\n",
      "[0.28735632]\n",
      "[0.96551724]\n",
      "[0.81609195]\n",
      "[0.79310345]\n",
      "[0.71264368]\n",
      "[0.50574713]\n",
      "[0.04597701]\n",
      "[0.29885057]\n",
      "[0.77011494]\n",
      "[0.51724138]\n",
      "[0.50574713]\n",
      "[0.08045977]\n",
      "[0.94252874]\n",
      "[0.22988506]\n",
      "[0.66666667]\n",
      "[0.47126437]\n",
      "[0.67816092]\n",
      "[0.4137931]\n",
      "[1.]\n",
      "[0.86206897]\n",
      "[0.74712644]\n",
      "[0.45977011]\n",
      "[0.33333333]\n",
      "[0.35632184]\n",
      "[0.71264368]\n",
      "[0.24137931]\n",
      "[0.50574713]\n",
      "[0.2183908]\n",
      "[0.70114943]\n",
      "[0.01149425]\n",
      "[0.02298851]\n",
      "[0.35632184]\n",
      "[0.73563218]\n",
      "[0.91954023]\n",
      "[0.55172414]\n",
      "[0.14942529]\n",
      "[0.56321839]\n",
      "[0.93103448]\n",
      "[0.16091954]\n",
      "[0.66666667]\n",
      "[0.20689655]\n",
      "[0.02298851]\n",
      "[0.48275862]\n",
      "[0.08045977]\n",
      "[0.52873563]\n",
      "[0.55172414]\n",
      "[0.85057471]\n",
      "[0.82758621]\n",
      "[0.6091954]\n",
      "[0.01149425]\n",
      "[0.83908046]\n",
      "[0.8045977]\n",
      "[0.26436782]\n",
      "[0.91954023]\n",
      "[0.08045977]\n",
      "[0.81609195]\n",
      "[0.31034483]\n",
      "[0.04597701]\n",
      "[0.55172414]\n",
      "[0.17241379]\n",
      "[0.33333333]\n",
      "[0.16091954]\n",
      "[0.75862069]\n",
      "[0.48275862]\n",
      "[0.49425287]\n",
      "[0.62068966]\n",
      "[0.85057471]\n",
      "[0.8045977]\n",
      "[0.13793103]\n",
      "[0.88505747]\n",
      "[0.72413793]\n",
      "[0.12643678]\n",
      "[0.43678161]\n",
      "[0.45977011]\n",
      "[0.59770115]\n",
      "[0.56321839]\n",
      "[0.34482759]\n",
      "[0.06896552]\n",
      "[0.77011494]\n",
      "[0.57471264]\n",
      "[0.09195402]\n",
      "[0.16091954]\n",
      "[0.95402299]\n",
      "[0.48275862]\n",
      "[0.26436782]\n",
      "[0.77011494]\n",
      "[0.3908046]\n",
      "[0.02298851]\n",
      "[0.81609195]\n",
      "[0.52873563]\n",
      "[0.47126437]\n",
      "[0.18390805]\n",
      "[0.82758621]\n",
      "[0.87356322]\n",
      "[0.3908046]\n",
      "[0.77011494]\n",
      "[0.31034483]\n",
      "[0.59770115]\n",
      "[0.13793103]\n",
      "[0.27586207]\n",
      "[0.88505747]\n",
      "[0.26436782]\n",
      "[0.88505747]\n",
      "[0.08045977]\n",
      "[0.42528736]\n",
      "[0.89655172]\n",
      "[0.50574713]\n",
      "[0.98850575]\n",
      "[0.90804598]\n",
      "[0.87356322]\n",
      "[0.32183908]\n",
      "[0.18390805]\n",
      "[0.66666667]\n",
      "[0.98850575]\n",
      "[0.06896552]\n",
      "[0.49425287]\n",
      "[1.]\n",
      "[0.8045977]\n",
      "[0.63218391]\n",
      "[0.56321839]\n",
      "[0.62068966]\n",
      "[0.08045977]\n",
      "[0.82758621]\n",
      "[0.6091954]\n",
      "[0.52873563]\n",
      "[0.36781609]\n",
      "[0.3908046]\n",
      "[0.56321839]\n",
      "[0.33333333]\n",
      "[0.93103448]\n",
      "[0.64367816]\n",
      "[0.73563218]\n",
      "[0.54022989]\n",
      "[0.82758621]\n",
      "[0.18390805]\n",
      "[0.96551724]\n",
      "[0.65517241]\n",
      "[0.65517241]\n",
      "[0.1954023]\n",
      "[0.50574713]\n",
      "[0.55172414]\n",
      "[0.3908046]\n",
      "[0.82758621]\n",
      "[0.62068966]\n",
      "[0.04597701]\n",
      "[0.4137931]\n",
      "[0.75862069]\n",
      "[0.11494253]\n",
      "[0.55172414]\n",
      "[0.09195402]\n",
      "[0.40229885]\n",
      "[0.82758621]\n",
      "[0.04597701]\n",
      "[0.40229885]\n",
      "[1.]\n",
      "[0.93103448]\n",
      "[0.90804598]\n",
      "[0.2183908]\n",
      "[0.64367816]\n",
      "[0.63218391]\n",
      "[0.4137931]\n",
      "[0.44827586]\n",
      "[0.88505747]\n",
      "[0.63218391]\n",
      "[0.72413793]\n",
      "[0.8045977]\n",
      "[1.]\n",
      "[0.20689655]\n",
      "[0.6091954]\n",
      "[0.03448276]\n",
      "[0.50574713]\n",
      "[0.57471264]\n",
      "[0.62068966]\n",
      "[0.12643678]\n",
      "[0.29885057]\n",
      "[0.26436782]\n",
      "[0.88505747]\n",
      "[0.49425287]\n",
      "[0.22988506]\n",
      "[0.28735632]\n",
      "[0.90804598]\n",
      "[0.57471264]\n",
      "[0.7816092]\n",
      "[0.72413793]\n",
      "[0.02298851]\n",
      "[0.55172414]\n",
      "[0.98850575]\n",
      "[0.6091954]\n",
      "[0.25287356]\n",
      "[0.18390805]\n",
      "[0.54022989]\n",
      "[0.70114943]\n",
      "[0.28735632]\n",
      "[0.90804598]\n",
      "[0.]\n",
      "[0.75862069]\n",
      "[0.54022989]\n",
      "[0.47126437]\n",
      "[0.83908046]\n",
      "[0.7816092]\n",
      "[0.50574713]\n",
      "[0.59770115]\n",
      "[0.45977011]\n",
      "[0.43678161]\n",
      "[0.16091954]\n",
      "[1.]\n",
      "[0.17241379]\n",
      "[0.59770115]\n",
      "[0.20689655]\n",
      "[0.79310345]\n",
      "[0.7816092]\n",
      "[0.14942529]\n",
      "[0.29885057]\n",
      "[0.25287356]\n",
      "[0.48275862]\n",
      "[0.25287356]\n",
      "[0.03448276]\n",
      "[0.77011494]\n",
      "[0.11494253]\n",
      "[0.57471264]\n",
      "[0.45977011]\n",
      "[0.73563218]\n",
      "[0.96551724]\n",
      "[0.67816092]\n",
      "[0.50574713]\n",
      "[0.35632184]\n",
      "[0.54022989]\n",
      "[0.81609195]\n",
      "[0.20689655]\n",
      "[0.04597701]\n",
      "[0.37931034]\n",
      "[0.31034483]\n",
      "[0.52873563]\n",
      "[0.37931034]\n",
      "[0.40229885]\n",
      "[0.68965517]\n",
      "[0.40229885]\n",
      "[0.62068966]\n",
      "[0.1954023]\n",
      "[0.72413793]\n",
      "[0.63218391]\n",
      "[0.27586207]\n",
      "[0.62068966]\n",
      "[0.94252874]\n",
      "[0.56321839]\n",
      "[0.44827586]\n",
      "[0.81609195]\n",
      "[0.28735632]\n",
      "[0.70114943]\n",
      "[0.85057471]\n",
      "[0.8045977]\n",
      "[0.44827586]\n",
      "[0.94252874]\n",
      "[0.6091954]\n",
      "[0.52873563]\n",
      "[0.48275862]\n",
      "[0.95402299]\n",
      "[0.42528736]\n",
      "[0.22988506]\n",
      "[0.44827586]\n",
      "[0.26436782]\n",
      "[0.43678161]\n",
      "[0.94252874]\n",
      "[0.34482759]\n",
      "[0.59770115]\n",
      "[0.45977011]\n",
      "[0.48275862]\n",
      "[0.91954023]\n",
      "[0.50574713]\n",
      "[0.64367816]\n",
      "[0.14942529]\n",
      "[0.7816092]\n",
      "[0.65517241]\n",
      "[0.17241379]\n",
      "[0.65517241]\n",
      "[0.83908046]\n",
      "[0.35632184]\n",
      "[0.96551724]\n",
      "[0.95402299]\n",
      "[0.51724138]\n",
      "[0.7816092]\n",
      "[0.94252874]\n",
      "[0.20689655]\n",
      "[0.64367816]\n",
      "[0.50574713]\n",
      "[0.10344828]\n",
      "[0.96551724]\n",
      "[1.]\n",
      "[0.88505747]\n",
      "[0.85057471]\n",
      "[0.94252874]\n",
      "[0.93103448]\n",
      "[0.56321839]\n",
      "[0.66666667]\n",
      "[0.66666667]\n",
      "[0.26436782]\n",
      "[0.13793103]\n",
      "[0.59770115]\n",
      "[0.08045977]\n",
      "[0.32183908]\n",
      "[0.51724138]\n",
      "[0.03448276]\n",
      "[0.31034483]\n",
      "[0.33333333]\n",
      "[0.3908046]\n",
      "[0.85057471]\n",
      "[0.]\n",
      "[0.73563218]\n",
      "[0.65517241]\n",
      "[0.81609195]\n",
      "[0.12643678]\n",
      "[0.93103448]\n",
      "[0.90804598]\n",
      "[1.]\n",
      "[0.66666667]\n",
      "[0.43678161]\n",
      "[0.68965517]\n",
      "[0.77011494]\n",
      "[0.89655172]\n",
      "[0.75862069]\n",
      "[0.57471264]\n",
      "[0.16091954]\n",
      "[0.82758621]\n",
      "[0.31034483]\n",
      "[0.81609195]\n",
      "[0.20689655]\n",
      "[0.4137931]\n",
      "[0.83908046]\n",
      "[0.73563218]\n",
      "[0.55172414]\n",
      "[0.75862069]\n",
      "[0.91954023]\n",
      "[0.86206897]\n",
      "[0.59770115]\n",
      "[0.54022989]\n",
      "[0.32183908]\n",
      "[0.73563218]\n",
      "[0.35632184]\n",
      "[0.65517241]\n",
      "[0.43678161]\n",
      "[0.54022989]\n",
      "[0.32183908]\n",
      "[0.43678161]\n",
      "[0.70114943]\n",
      "[0.03448276]\n",
      "[0.08045977]\n",
      "[0.5862069]\n",
      "[0.52873563]\n",
      "[0.56321839]\n",
      "[0.95402299]\n",
      "[0.8045977]\n",
      "[0.32183908]\n",
      "[0.36781609]\n",
      "[0.72413793]\n",
      "[0.16091954]\n",
      "[0.73563218]\n",
      "[0.51724138]\n",
      "[0.73563218]\n",
      "[0.96551724]\n",
      "[0.10344828]\n",
      "[0.3908046]\n",
      "[0.74712644]\n",
      "[0.79310345]\n",
      "[0.32183908]\n",
      "[0.83908046]\n",
      "[0.11494253]\n",
      "[0.45977011]\n",
      "[0.77011494]\n",
      "[0.57471264]\n",
      "[0.04597701]\n",
      "[0.81609195]\n",
      "[0.71264368]\n",
      "[0.68965517]\n",
      "[0.97701149]\n",
      "[0.8045977]\n",
      "[0.93103448]\n",
      "[0.05747126]\n",
      "[0.55172414]\n",
      "[0.47126437]\n",
      "[0.98850575]\n",
      "[0.45977011]\n",
      "[0.81609195]\n",
      "[0.13793103]\n",
      "[0.45977011]\n",
      "[0.37931034]\n",
      "[0.37931034]\n",
      "[0.86206897]\n"
     ]
    }
   ],
   "source": [
    "#print scaled data \n",
    "for i in scaled_train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------initialize the simple sequential model -----------------------------------------'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"-------------------------------------initialize the simple sequential model -----------------------------------------\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras#keras api is comming from tf bydefault\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "#basic type of model used in keras other one is functional\n",
    "\"\"\"here speciality is that we get all the performing units from keras\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "#activation and fully connected laters in this import what layers we use in the network(another type is pool)\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "#adam is a optimizer like gradient descent\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#this is the loss function\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this set of code is used when using gpu to run the session in tensorflow'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"this set of code is used when using gpu to run the session in tensorflow\"\"\"\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(\"num of GPUs available : \", len(physical_devices))\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)#this is to run the code in the define gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#define the model we use for the nn and here we use plain sequential n\n",
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape = (1, ), activation = 'relu'),\n",
    "    Dense(units = 32, activation = 'relu'),\n",
    "    Dense(units = 2, activation = 'softmax')\n",
    "])\n",
    "#in this plain nn i used three dense/fully connected layer and these defined layers are hidden layers \n",
    "#input layer is not included in the sequential and for the first dense layer inputs are given and it has one row and \n",
    "#several columns and last later \"softmax\" is the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#from this can get how the nn is formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---------------------------------train the data set using simple sequential model -----------------------------------'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"---------------------------------train the data set using simple sequential model -----------------------------------\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"declare the model created\"\"\"\n",
    "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "#learning rate is the alpha\n",
    "#metrics means a function that is used to judge the performance of your model.here i use the accuracy as the paramere to \n",
    "#measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2100/2100 - 1s - loss: 0.6742 - acc: 0.5533\n",
      "Epoch 2/50\n",
      "2100/2100 - 0s - loss: 0.6351 - acc: 0.6148\n",
      "Epoch 3/50\n",
      "2100/2100 - 0s - loss: 0.5943 - acc: 0.7090\n",
      "Epoch 4/50\n",
      "2100/2100 - 0s - loss: 0.5501 - acc: 0.7705\n",
      "Epoch 5/50\n",
      "2100/2100 - 0s - loss: 0.5125 - acc: 0.8010\n",
      "Epoch 6/50\n",
      "2100/2100 - 0s - loss: 0.4773 - acc: 0.8310\n",
      "Epoch 7/50\n",
      "2100/2100 - 0s - loss: 0.4451 - acc: 0.8471\n",
      "Epoch 8/50\n",
      "2100/2100 - 0s - loss: 0.4162 - acc: 0.8695\n",
      "Epoch 9/50\n",
      "2100/2100 - 0s - loss: 0.3909 - acc: 0.8890\n",
      "Epoch 10/50\n",
      "2100/2100 - 0s - loss: 0.3691 - acc: 0.8952\n",
      "Epoch 11/50\n",
      "2100/2100 - 0s - loss: 0.3507 - acc: 0.9095\n",
      "Epoch 12/50\n",
      "2100/2100 - 0s - loss: 0.3354 - acc: 0.9143\n",
      "Epoch 13/50\n",
      "2100/2100 - 0s - loss: 0.3228 - acc: 0.9195\n",
      "Epoch 14/50\n",
      "2100/2100 - 0s - loss: 0.3127 - acc: 0.9214\n",
      "Epoch 15/50\n",
      "2100/2100 - 0s - loss: 0.3041 - acc: 0.9305\n",
      "Epoch 16/50\n",
      "2100/2100 - 0s - loss: 0.2972 - acc: 0.9290\n",
      "Epoch 17/50\n",
      "2100/2100 - 0s - loss: 0.2917 - acc: 0.9333\n",
      "Epoch 18/50\n",
      "2100/2100 - 0s - loss: 0.2866 - acc: 0.9352\n",
      "Epoch 19/50\n",
      "2100/2100 - 0s - loss: 0.2828 - acc: 0.9343\n",
      "Epoch 20/50\n",
      "2100/2100 - 0s - loss: 0.2789 - acc: 0.9319\n",
      "Epoch 21/50\n",
      "2100/2100 - 0s - loss: 0.2755 - acc: 0.9414\n",
      "Epoch 22/50\n",
      "2100/2100 - 0s - loss: 0.2732 - acc: 0.9367\n",
      "Epoch 23/50\n",
      "2100/2100 - 0s - loss: 0.2707 - acc: 0.9376\n",
      "Epoch 24/50\n",
      "2100/2100 - 0s - loss: 0.2684 - acc: 0.9386\n",
      "Epoch 25/50\n",
      "2100/2100 - 0s - loss: 0.2662 - acc: 0.9386\n",
      "Epoch 26/50\n",
      "2100/2100 - 0s - loss: 0.2641 - acc: 0.9386\n",
      "Epoch 27/50\n",
      "2100/2100 - 0s - loss: 0.2621 - acc: 0.9429\n",
      "Epoch 28/50\n",
      "2100/2100 - 0s - loss: 0.2608 - acc: 0.9376\n",
      "Epoch 29/50\n",
      "2100/2100 - 0s - loss: 0.2592 - acc: 0.9405\n",
      "Epoch 30/50\n",
      "2100/2100 - 0s - loss: 0.2578 - acc: 0.9414\n",
      "Epoch 31/50\n",
      "2100/2100 - 0s - loss: 0.2565 - acc: 0.9390\n",
      "Epoch 32/50\n",
      "2100/2100 - 0s - loss: 0.2553 - acc: 0.9419\n",
      "Epoch 33/50\n",
      "2100/2100 - 0s - loss: 0.2543 - acc: 0.9414\n",
      "Epoch 34/50\n",
      "2100/2100 - 0s - loss: 0.2533 - acc: 0.9462\n",
      "Epoch 35/50\n",
      "2100/2100 - 0s - loss: 0.2522 - acc: 0.9462\n",
      "Epoch 36/50\n",
      "2100/2100 - 0s - loss: 0.2518 - acc: 0.9424\n",
      "Epoch 37/50\n",
      "2100/2100 - 0s - loss: 0.2509 - acc: 0.9424\n",
      "Epoch 38/50\n",
      "2100/2100 - 0s - loss: 0.2501 - acc: 0.9476\n",
      "Epoch 39/50\n",
      "2100/2100 - 0s - loss: 0.2496 - acc: 0.9476\n",
      "Epoch 40/50\n",
      "2100/2100 - 0s - loss: 0.2488 - acc: 0.9457\n",
      "Epoch 41/50\n",
      "2100/2100 - 0s - loss: 0.2482 - acc: 0.9476\n",
      "Epoch 42/50\n",
      "2100/2100 - 0s - loss: 0.2476 - acc: 0.9476\n",
      "Epoch 43/50\n",
      "2100/2100 - 0s - loss: 0.2470 - acc: 0.9452\n",
      "Epoch 44/50\n",
      "2100/2100 - 0s - loss: 0.2465 - acc: 0.9462\n",
      "Epoch 45/50\n",
      "2100/2100 - 0s - loss: 0.2460 - acc: 0.9476\n",
      "Epoch 46/50\n",
      "2100/2100 - 0s - loss: 0.2455 - acc: 0.9476\n",
      "Epoch 47/50\n",
      "2100/2100 - 0s - loss: 0.2449 - acc: 0.9476\n",
      "Epoch 48/50\n",
      "2100/2100 - 0s - loss: 0.2446 - acc: 0.9476\n",
      "Epoch 49/50\n",
      "2100/2100 - 0s - loss: 0.2443 - acc: 0.9481\n",
      "Epoch 50/50\n",
      "2100/2100 - 0s - loss: 0.2437 - acc: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e27522748>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lets run the fit for the data set to the model\"\"\"\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "model.fit(x = scaled_train_samples, y = train_labels, batch_size = 10, epochs = 50, shuffle = True, verbose = 2)\n",
    "#here x and y are given as numpy arrays\n",
    "#mini batch size\n",
    "#no of rounds around full data set\n",
    "#verbose is responsible for how we see the progress of the internal operations \n",
    "#if verbose = 2 -------> Epoch 1/50 this is how progress is shown in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is used to know that our data set trained is subjected to overfitting and in this we use fit function and it is \\nadvantageous to shuffles the data set before doing the fit'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"---------------------------------how to use cross validation set -----------------------------------\"\"\"\n",
    "\"\"\"this is used to know that our data set trained is subjected to overfitting and in this we use fit function and it is \n",
    "advantageous to shuffles the data set before doing the fit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/50\n",
      "1890/1890 - 1s - loss: 0.2438 - acc: 0.9466 - val_loss: 0.2397 - val_acc: 0.9571\n",
      "Epoch 2/50\n",
      "1890/1890 - 0s - loss: 0.2437 - acc: 0.9466 - val_loss: 0.2386 - val_acc: 0.9571\n",
      "Epoch 3/50\n",
      "1890/1890 - 0s - loss: 0.2432 - acc: 0.9466 - val_loss: 0.2380 - val_acc: 0.9571\n",
      "Epoch 4/50\n",
      "1890/1890 - 0s - loss: 0.2430 - acc: 0.9466 - val_loss: 0.2385 - val_acc: 0.9571\n",
      "Epoch 5/50\n",
      "1890/1890 - 0s - loss: 0.2428 - acc: 0.9460 - val_loss: 0.2373 - val_acc: 0.9571\n",
      "Epoch 6/50\n",
      "1890/1890 - 0s - loss: 0.2426 - acc: 0.9466 - val_loss: 0.2374 - val_acc: 0.9571\n",
      "Epoch 7/50\n",
      "1890/1890 - 0s - loss: 0.2423 - acc: 0.9466 - val_loss: 0.2370 - val_acc: 0.9571\n",
      "Epoch 8/50\n",
      "1890/1890 - 0s - loss: 0.2420 - acc: 0.9466 - val_loss: 0.2366 - val_acc: 0.9571\n",
      "Epoch 9/50\n",
      "1890/1890 - 0s - loss: 0.2417 - acc: 0.9466 - val_loss: 0.2362 - val_acc: 0.9571\n",
      "Epoch 10/50\n",
      "1890/1890 - 1s - loss: 0.2415 - acc: 0.9444 - val_loss: 0.2350 - val_acc: 0.9571\n",
      "Epoch 11/50\n",
      "1890/1890 - 0s - loss: 0.2413 - acc: 0.9471 - val_loss: 0.2351 - val_acc: 0.9571\n",
      "Epoch 12/50\n",
      "1890/1890 - 0s - loss: 0.2411 - acc: 0.9466 - val_loss: 0.2351 - val_acc: 0.9571\n",
      "Epoch 13/50\n",
      "1890/1890 - 0s - loss: 0.2409 - acc: 0.9466 - val_loss: 0.2346 - val_acc: 0.9571\n",
      "Epoch 14/50\n",
      "1890/1890 - 0s - loss: 0.2405 - acc: 0.9466 - val_loss: 0.2358 - val_acc: 0.9571\n",
      "Epoch 15/50\n",
      "1890/1890 - 0s - loss: 0.2404 - acc: 0.9471 - val_loss: 0.2343 - val_acc: 0.9571\n",
      "Epoch 16/50\n",
      "1890/1890 - 0s - loss: 0.2402 - acc: 0.9466 - val_loss: 0.2335 - val_acc: 0.9571\n",
      "Epoch 17/50\n",
      "1890/1890 - 0s - loss: 0.2400 - acc: 0.9466 - val_loss: 0.2332 - val_acc: 0.9571\n",
      "Epoch 18/50\n",
      "1890/1890 - 0s - loss: 0.2397 - acc: 0.9466 - val_loss: 0.2337 - val_acc: 0.9571\n",
      "Epoch 19/50\n",
      "1890/1890 - 0s - loss: 0.2396 - acc: 0.9466 - val_loss: 0.2330 - val_acc: 0.9571\n",
      "Epoch 20/50\n",
      "1890/1890 - 0s - loss: 0.2394 - acc: 0.9466 - val_loss: 0.2334 - val_acc: 0.9571\n",
      "Epoch 21/50\n",
      "1890/1890 - 0s - loss: 0.2391 - acc: 0.9471 - val_loss: 0.2336 - val_acc: 0.9571\n",
      "Epoch 22/50\n",
      "1890/1890 - 0s - loss: 0.2390 - acc: 0.9466 - val_loss: 0.2326 - val_acc: 0.9571\n",
      "Epoch 23/50\n",
      "1890/1890 - 0s - loss: 0.2389 - acc: 0.9466 - val_loss: 0.2338 - val_acc: 0.9571\n",
      "Epoch 24/50\n",
      "1890/1890 - 0s - loss: 0.2387 - acc: 0.9466 - val_loss: 0.2328 - val_acc: 0.9571\n",
      "Epoch 25/50\n",
      "1890/1890 - 0s - loss: 0.2385 - acc: 0.9476 - val_loss: 0.2328 - val_acc: 0.9571\n",
      "Epoch 26/50\n",
      "1890/1890 - 0s - loss: 0.2383 - acc: 0.9466 - val_loss: 0.2316 - val_acc: 0.9571\n",
      "Epoch 27/50\n",
      "1890/1890 - 1s - loss: 0.2381 - acc: 0.9466 - val_loss: 0.2307 - val_acc: 0.9571\n",
      "Epoch 28/50\n",
      "1890/1890 - 0s - loss: 0.2379 - acc: 0.9466 - val_loss: 0.2301 - val_acc: 0.9571\n",
      "Epoch 29/50\n",
      "1890/1890 - 0s - loss: 0.2377 - acc: 0.9466 - val_loss: 0.2296 - val_acc: 0.9571\n",
      "Epoch 30/50\n",
      "1890/1890 - 0s - loss: 0.2378 - acc: 0.9466 - val_loss: 0.2293 - val_acc: 0.9571\n",
      "Epoch 31/50\n",
      "1890/1890 - 0s - loss: 0.2375 - acc: 0.9471 - val_loss: 0.2300 - val_acc: 0.9571\n",
      "Epoch 32/50\n",
      "1890/1890 - 0s - loss: 0.2373 - acc: 0.9466 - val_loss: 0.2296 - val_acc: 0.9571\n",
      "Epoch 33/50\n",
      "1890/1890 - 0s - loss: 0.2372 - acc: 0.9471 - val_loss: 0.2293 - val_acc: 0.9571\n",
      "Epoch 34/50\n",
      "1890/1890 - 0s - loss: 0.2370 - acc: 0.9466 - val_loss: 0.2287 - val_acc: 0.9571\n",
      "Epoch 35/50\n",
      "1890/1890 - 0s - loss: 0.2368 - acc: 0.9471 - val_loss: 0.2284 - val_acc: 0.9571\n",
      "Epoch 36/50\n",
      "1890/1890 - 0s - loss: 0.2366 - acc: 0.9460 - val_loss: 0.2285 - val_acc: 0.9571\n",
      "Epoch 37/50\n",
      "1890/1890 - 0s - loss: 0.2366 - acc: 0.9466 - val_loss: 0.2287 - val_acc: 0.9571\n",
      "Epoch 38/50\n",
      "1890/1890 - 0s - loss: 0.2364 - acc: 0.9466 - val_loss: 0.2278 - val_acc: 0.9571\n",
      "Epoch 39/50\n",
      "1890/1890 - 0s - loss: 0.2361 - acc: 0.9466 - val_loss: 0.2283 - val_acc: 0.9571\n",
      "Epoch 40/50\n",
      "1890/1890 - 0s - loss: 0.2361 - acc: 0.9487 - val_loss: 0.2265 - val_acc: 0.9619\n",
      "Epoch 41/50\n",
      "1890/1890 - 0s - loss: 0.2359 - acc: 0.9466 - val_loss: 0.2268 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "1890/1890 - 0s - loss: 0.2358 - acc: 0.9481 - val_loss: 0.2275 - val_acc: 0.9571\n",
      "Epoch 43/50\n",
      "1890/1890 - 0s - loss: 0.2355 - acc: 0.9466 - val_loss: 0.2267 - val_acc: 0.9571\n",
      "Epoch 44/50\n",
      "1890/1890 - 1s - loss: 0.2355 - acc: 0.9476 - val_loss: 0.2278 - val_acc: 0.9571\n",
      "Epoch 45/50\n",
      "1890/1890 - 0s - loss: 0.2353 - acc: 0.9466 - val_loss: 0.2260 - val_acc: 0.9571\n",
      "Epoch 46/50\n",
      "1890/1890 - 0s - loss: 0.2353 - acc: 0.9466 - val_loss: 0.2265 - val_acc: 0.9571\n",
      "Epoch 47/50\n",
      "1890/1890 - 0s - loss: 0.2350 - acc: 0.9476 - val_loss: 0.2274 - val_acc: 0.9571\n",
      "Epoch 48/50\n",
      "1890/1890 - 0s - loss: 0.2350 - acc: 0.9476 - val_loss: 0.2275 - val_acc: 0.9571\n",
      "Epoch 49/50\n",
      "1890/1890 - 0s - loss: 0.2347 - acc: 0.9466 - val_loss: 0.2254 - val_acc: 0.9571\n",
      "Epoch 50/50\n",
      "1890/1890 - 0s - loss: 0.2346 - acc: 0.9466 - val_loss: 0.2257 - val_acc: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e277a7888>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = scaled_train_samples, y = train_labels, validation_split = 0.1, batch_size = 10, epochs = 50, shuffle = True, verbose = 2)\n",
    "#as validation_split is 0.1 it means that 1/10 of the data set is used for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creating the test set and here we create the lables also and in a real \\ndata set there is no labels and here we use them for further understanding'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"creating the test set and here we create the lables also and in a real \n",
    "data set there is no labels and here we use them for further understanding\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []#list to store the testing x values\n",
    "test_labels = []#list to store the testing y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here it go we have made a data set for testing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get 50 people in both older and younger \n",
    "for i in range (10):\n",
    "    # 5% of youngers who have side effects\n",
    "    random_younger = randint(13, 64)#this generates a random number between 13 and 64 \n",
    "    test_samples.append(random_younger)#assing random value to the list\n",
    "    test_labels.append(1)#as having side effects set to 1\n",
    "    \n",
    "    #5% of olders who haven't side effects\n",
    "    random_older = randint(65, 100)#this generates a random number between 13 and 64 \n",
    "    test_samples.append(random_older)#assing random value to the list\n",
    "    test_labels.append(0)#as not having side effects set to 0\n",
    "    \n",
    "#to get 1000 people in both older and younger \n",
    "for i in range (200):\n",
    "    # 95% of youngers who donot have side effects\n",
    "    random_younger = randint(13, 64)#this generates a random number between 13 and 64 \n",
    "    test_samples.append(random_younger)#assing random value to the list\n",
    "    test_labels.append(0)#as having side effects set to 1\n",
    "    \n",
    "    #95% of olders who haven't side effects\n",
    "    random_older = randint(65, 100)#this generates a random number between 13 and 64 \n",
    "    test_samples.append(random_older)#assing random value to the list\n",
    "    test_labels.append(1)#as not having side effects set to 0    \n",
    "    \n",
    "\"\"\"here it go we have made a data set for testing\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the both lists to numpy arrays as for fit function to send\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "#to remove any order of the data sets(arrays) have to shuffle\n",
    "test_samples, test_labels = shuffle(test_samples, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this is where we use our trained model to predict for the test set\"\"\"\n",
    "predictions = model.predict(x = scaled_test_samples, batch_size = 10, verbose = 0)\n",
    "#here no epochs because here one time output is needed as this is a prediction\n",
    "#verbose is zero as no output representation is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"here out put is converted to softmax values 0,1,... as it the final predictio\n",
    "and as here we use two classes we use only 0 and 1\"\"\"\n",
    "rounded_prediction = np.argmax(predictions, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#printing the predictions \n",
    "for i in rounded_prediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creating the confusion matrix'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"creating the confusion matrix\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix#importing confusion matrix\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true = test_labels, y_pred = rounded_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "     \n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else :\n",
    "        print('confusion matrix without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max()/2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], \n",
    "                 horizontalalignment = \"center\", \n",
    "                 color = \"white\" if cm[i, j]>thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix without normalization\n",
      "[[196  14]\n",
      " [  8 202]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm = cm, classes = cm_plot_labels, title = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Method1: model.save()\\n--------------------------\\nIn this method save the data in a .h5 file\\n\\nfunctionalities that are saved with the file : \\n1.architecture of the model help to recreate the model\\n2.weights of the model\\n3.training configurations (loss, optimizer)\\n4.state of the optimizer allowing to resume the trainig where it was left off'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Method1: model.save()\n",
    "--------------------------\n",
    "In this method save the data in a .h5 file\n",
    "\n",
    "functionalities that are saved with the file : \n",
    "1.architecture of the model help to recreate the model\n",
    "2.weights of the model\n",
    "3.training configurations (loss, optimizer)\n",
    "4.state of the optimizer allowing to resume the trainig where it was left off\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks first to see if the file exits already\n",
    "#if not the model is saved to disk\n",
    "import os.path\n",
    "if os.path.isfile('.../... .h5') is False:\n",
    "    model.save('.../... .h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#lets import the saved data back\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('.../... .h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4093287 ,  0.25210342, -0.34808785,  0.45023108,  0.412813  ,\n",
       "         -0.21525353,  0.26369214,  0.34644312, -0.4424731 , -0.22250843,\n",
       "          0.4808833 ,  0.5022649 , -0.46146315, -0.3225867 , -0.47280145,\n",
       "          0.42650238]], dtype=float32),\n",
       " array([-0.14964987, -0.12730871,  0.        , -0.21584168,  0.18280591,\n",
       "         0.        , -0.13383721, -0.1717963 ,  0.        ,  0.        ,\n",
       "        -0.15267558, -0.20154907,  0.        ,  0.        ,  0.        ,\n",
       "        -0.12203234], dtype=float32),\n",
       " array([[-0.05842839, -0.0570063 ,  0.03629612, -0.40347627,  0.48671895,\n",
       "          0.58621794, -0.02511803, -0.5059574 , -0.11812633, -0.39847007,\n",
       "          0.01330848, -0.11090126,  0.02550291, -0.49429134,  0.2128234 ,\n",
       "          0.5662344 , -0.36216214,  0.45464176, -0.28637815,  0.0879114 ,\n",
       "         -0.02629294,  0.57261586, -0.12781513, -0.33431083,  0.21736269,\n",
       "          0.18811812, -0.21865855, -0.02999391,  0.47832912, -0.00180573,\n",
       "          0.53040993,  0.02222187],\n",
       "        [-0.5595146 ,  0.09615415,  0.3536138 , -0.76516485,  0.2979886 ,\n",
       "          0.4727579 , -0.887284  , -0.7780373 ,  0.03205531, -0.781714  ,\n",
       "         -0.6091586 , -0.4019171 ,  0.28111053, -0.5230378 ,  0.13022351,\n",
       "          0.23623389, -0.53761435,  0.47448435, -0.03987244, -0.7656634 ,\n",
       "          0.2582041 ,  0.4450029 , -0.0079827 ,  0.29968885, -0.09551629,\n",
       "         -0.33518142, -0.77032363,  0.12826172,  0.52901816, -0.61587906,\n",
       "          0.28173882, -0.7815943 ],\n",
       "        [ 0.03294325, -0.17804   ,  0.00535038, -0.24611138,  0.06967142,\n",
       "         -0.25468633, -0.18594372, -0.15432313, -0.2575662 , -0.02467486,\n",
       "         -0.05371371, -0.0219537 ,  0.27549896, -0.03826782,  0.35057697,\n",
       "         -0.02448168,  0.01234734, -0.04358262,  0.17210546, -0.2634276 ,\n",
       "         -0.23573685, -0.18698339,  0.31068465, -0.03854734,  0.09270486,\n",
       "         -0.2784825 ,  0.21058008, -0.13773489,  0.23946133,  0.0558728 ,\n",
       "          0.19905832, -0.15266836],\n",
       "        [ 0.07193125,  0.3240737 ,  0.46524534, -0.44548833,  0.23812363,\n",
       "          0.41322345, -0.38012385, -0.32690033,  0.31360745, -0.46490404,\n",
       "         -0.6810905 , -0.7248056 ,  0.48068368, -0.5869552 ,  0.0967762 ,\n",
       "          0.29387876, -0.6821159 ,  0.30323976, -0.0906662 , -0.24125054,\n",
       "          0.53931606, -0.0046313 , -0.34159786,  0.2853268 , -0.2759096 ,\n",
       "         -0.34429643, -0.6349766 , -0.11504386, -0.00301038, -0.16059776,\n",
       "          0.33072218, -0.6409162 ],\n",
       "        [ 0.14459558, -0.31690064,  0.32427135,  0.26669317,  0.25670478,\n",
       "         -0.21234518,  0.08080537,  0.3034174 ,  0.4116974 ,  0.12763084,\n",
       "          0.0239825 ,  0.22195072,  0.24824391,  0.07136254,  0.12780198,\n",
       "          0.18489788,  0.03824442,  0.22867364, -0.0674168 ,  0.05875724,\n",
       "          0.03946227, -0.07079587, -0.26164982, -0.29126152, -0.29000577,\n",
       "          0.0694674 ,  0.2162079 , -0.0299916 , -0.03006773,  0.04370306,\n",
       "          0.25249445, -0.13565442],\n",
       "        [-0.18768741, -0.26007867,  0.2762713 , -0.06321505, -0.02837983,\n",
       "         -0.07349542,  0.3366938 ,  0.04616621, -0.24145997, -0.13799864,\n",
       "         -0.33989242,  0.02241942, -0.08159184, -0.2077886 , -0.22522196,\n",
       "         -0.2594639 ,  0.13534304, -0.22742102, -0.11702527,  0.3050767 ,\n",
       "         -0.3173269 , -0.30642435, -0.2004992 , -0.2429882 ,  0.1765438 ,\n",
       "          0.05023128,  0.2406852 , -0.06050044, -0.23971727,  0.28662518,\n",
       "          0.22491023, -0.2510408 ],\n",
       "        [-0.5454175 , -0.25911537,  0.5976051 , -0.7128187 ,  0.12116942,\n",
       "          0.15459229, -0.67877686, -0.8135843 ,  0.1542704 , -0.8039991 ,\n",
       "         -0.44550657, -0.80808955,  0.25541332, -0.8842957 ,  0.23823501,\n",
       "          0.393355  , -0.6056025 ,  0.63051355, -0.171296  , -0.59691274,\n",
       "          0.02428524,  0.21219458, -0.16487214, -0.17114241, -0.33700982,\n",
       "         -0.08914968, -0.83496636, -0.10004726,  0.53504723, -0.68657535,\n",
       "          0.20976488, -0.63816595],\n",
       "        [-0.4448564 , -0.02656576,  0.02459375, -0.3786536 ,  0.28710267,\n",
       "          0.49091533, -0.5462397 , -0.74734974,  0.0539497 , -0.8051694 ,\n",
       "         -0.3063558 , -0.6931553 ,  0.3684444 , -0.37675902,  0.38015422,\n",
       "          0.1163414 , -0.4721697 ,  0.46768114, -0.24218312, -0.4507888 ,\n",
       "          0.24332348,  0.5646058 , -0.24491087,  0.05703506,  0.28924933,\n",
       "         -0.23479828, -0.44217634, -0.16134395,  0.17691237, -0.7202324 ,\n",
       "          0.24845518, -0.2227845 ],\n",
       "        [ 0.21049234,  0.32849059, -0.00124669,  0.25186166, -0.13284686,\n",
       "         -0.3122079 , -0.09014115,  0.08815509,  0.05739382,  0.21254656,\n",
       "         -0.06207615,  0.11960331, -0.19236715,  0.1828591 , -0.18809025,\n",
       "         -0.17170432,  0.19495347,  0.31615356,  0.2982227 , -0.02623346,\n",
       "         -0.02291879,  0.1963447 , -0.31009382, -0.1982307 , -0.00259599,\n",
       "          0.18477723,  0.2651209 , -0.05200323, -0.19765802,  0.09650135,\n",
       "         -0.1124059 ,  0.06260332],\n",
       "        [-0.0439032 ,  0.33040246,  0.30932364,  0.06034231,  0.2572545 ,\n",
       "         -0.27819425,  0.03885072, -0.21863458,  0.19772956,  0.01608112,\n",
       "          0.30349353,  0.26219192, -0.33628127, -0.05052775, -0.25792834,\n",
       "         -0.15713078,  0.30430886, -0.03216606, -0.233951  , -0.08093938,\n",
       "         -0.21268252, -0.03394365,  0.10932067, -0.01955807,  0.05979288,\n",
       "          0.27253708, -0.32446575,  0.04317421, -0.09864208,  0.31513968,\n",
       "          0.25219098,  0.2788482 ],\n",
       "        [ 0.04377839, -0.25126213,  0.492355  , -0.2278536 , -0.00989056,\n",
       "          0.4496293 ,  0.00723728, -0.28629875,  0.46575195, -0.04000836,\n",
       "         -0.30969453, -0.12913507,  0.5571461 , -0.2084426 ,  0.47258854,\n",
       "          0.5796997 , -0.23546414,  0.11390783,  0.33619156, -0.14266579,\n",
       "          0.02830696,  0.42280585, -0.3066147 ,  0.04215714,  0.22411199,\n",
       "         -0.37693608, -0.3587285 , -0.0788195 ,  0.17802548, -0.11889941,\n",
       "         -0.02891619, -0.06787647],\n",
       "        [ 0.11410388, -0.20323758, -0.01154014, -0.00188176,  0.36653957,\n",
       "          0.62152576, -0.31139752, -0.44146907, -0.08778113, -0.16203651,\n",
       "         -0.3894386 , -0.5310789 ,  0.16676562, -0.25786847,  0.53211313,\n",
       "          0.31663567, -0.24208772,  0.45929343,  0.10484255, -0.29795676,\n",
       "          0.3743254 ,  0.39896706,  0.01313305, -0.15821446,  0.10689708,\n",
       "         -0.01120855, -0.6002588 , -0.23034096,  0.41799244, -0.29432273,\n",
       "          0.22957587,  0.01612818],\n",
       "        [ 0.24811092,  0.17921302,  0.2515646 ,  0.33518454, -0.21417409,\n",
       "         -0.3344188 , -0.24362126,  0.2941645 ,  0.29195055, -0.28138012,\n",
       "         -0.2971696 ,  0.04679936,  0.1960235 , -0.33669052,  0.22451404,\n",
       "          0.11437559, -0.10091642,  0.13747382, -0.18069921, -0.3303437 ,\n",
       "          0.26577088, -0.06172711, -0.20958574, -0.0149135 ,  0.19421789,\n",
       "         -0.2109196 , -0.33330056,  0.16352293, -0.11069953, -0.20651163,\n",
       "         -0.31324118, -0.21604045],\n",
       "        [-0.33768618,  0.0574728 , -0.00775874,  0.04981166,  0.25106403,\n",
       "         -0.1528307 , -0.22630692, -0.06933492,  0.06478763, -0.05061895,\n",
       "          0.2803448 ,  0.22735247,  0.13913012,  0.27159175, -0.08629349,\n",
       "         -0.11054578, -0.1664851 , -0.1491791 , -0.16717337,  0.3062851 ,\n",
       "          0.03683406,  0.10665151,  0.25252005, -0.27126968, -0.34106332,\n",
       "          0.02562308,  0.3303605 , -0.12288386,  0.12899944, -0.2505144 ,\n",
       "          0.28395024,  0.05179822],\n",
       "        [-0.0383929 ,  0.14905849,  0.17926875, -0.14225648,  0.19847456,\n",
       "          0.23198411, -0.03577712, -0.26445782, -0.30310404, -0.20453629,\n",
       "          0.22704914, -0.2327016 ,  0.1310766 , -0.02373466,  0.11112547,\n",
       "          0.1505498 , -0.05496067, -0.134665  ,  0.0495615 ,  0.13972077,\n",
       "         -0.20930554,  0.34134194, -0.07993731, -0.01657805, -0.28336194,\n",
       "         -0.06512809,  0.10501647, -0.02441585,  0.30684885,  0.18204   ,\n",
       "         -0.17482656,  0.26246038],\n",
       "        [ 0.07069897, -0.10506046,  0.34415948, -0.55674267, -0.09145198,\n",
       "          0.49051377, -0.35806188, -0.30524746,  0.4157154 , -0.06763834,\n",
       "         -0.30157784, -0.15122607, -0.08802352, -0.05050518,  0.30043828,\n",
       "         -0.11048019,  0.11811163,  0.07857118,  0.09833357, -0.3395646 ,\n",
       "          0.49832684,  0.35702884,  0.20097521, -0.08009797, -0.22246791,\n",
       "          0.12270213, -0.01580412,  0.12929603,  0.42803058, -0.17441912,\n",
       "          0.4574868 ,  0.1634794 ]], dtype=float32),\n",
       " array([ 0.06736734,  0.        , -0.16893455,  0.14626591, -0.12439593,\n",
       "        -0.05586279,  0.16578266,  0.18631153, -0.13245012,  0.15440959,\n",
       "         0.23145217,  0.15447691, -0.13077863,  0.2080699 , -0.12786679,\n",
       "        -0.1358834 ,  0.18621406, -0.13569064, -0.00051165,  0.15773354,\n",
       "        -0.07304076, -0.07417656,  0.        ,  0.        , -0.00071539,\n",
       "        -0.02776578,  0.18817143, -0.00196525, -0.07316091,  0.15117209,\n",
       "        -0.15583856,  0.14468528], dtype=float32),\n",
       " array([[ 0.2722188 ,  0.14916535],\n",
       "        [ 0.18333194, -0.41912112],\n",
       "        [-0.51981163,  0.07071213],\n",
       "        [ 0.6575762 , -0.64143807],\n",
       "        [-0.47383896,  0.6853648 ],\n",
       "        [-0.27773952,  0.40947348],\n",
       "        [ 0.7847714 , -0.80600554],\n",
       "        [ 0.87726086, -0.3717576 ],\n",
       "        [-0.52827406,  0.17785232],\n",
       "        [ 0.4037956 , -0.8201175 ],\n",
       "        [ 0.91988987, -0.12818138],\n",
       "        [ 0.5749893 , -0.86961067],\n",
       "        [-0.500947  ,  0.41781652],\n",
       "        [ 0.56839323, -0.6463232 ],\n",
       "        [-0.40951338,  0.48526433],\n",
       "        [ 0.0444278 ,  0.62277406],\n",
       "        [ 0.5866652 , -0.9056791 ],\n",
       "        [-0.31229094,  0.38743475],\n",
       "        [ 0.32952967,  0.36256692],\n",
       "        [ 0.266446  , -0.74680066],\n",
       "        [-0.55121535,  0.3452226 ],\n",
       "        [-0.70888394,  0.2297449 ],\n",
       "        [-0.39542407,  0.19196668],\n",
       "        [-0.22317946,  0.34811702],\n",
       "        [-0.35734957,  0.26755357],\n",
       "        [-0.09172707, -0.0314202 ],\n",
       "        [ 0.6893141 , -0.8775441 ],\n",
       "        [-0.14964347, -0.03306129],\n",
       "        [-0.2861205 ,  0.65408444],\n",
       "        [ 0.59941286, -0.10974403],\n",
       "        [-0.6781361 , -0.11121553],\n",
       "        [ 0.53881836, -0.3831432 ]], dtype=float32),\n",
       " array([ 0.07402164, -0.07402164], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x26dd94bb188>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer #it can be shown that optimizer is adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this storing method only the model architecture get stored and we have to train the model again to get the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.to_json()\"\"\"\n",
    "#save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "#save as YAML\n",
    "#yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string#here it gives a json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as seen above the this in not in the model architecture in the dictionary\n",
    "#so we have to reconstruct the model from the json object\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)\n",
    "\n",
    "#model reconstruction from YAML\n",
    "#from tensorflow.keras.model import model_from_yaml\n",
    "#model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.save_weights()\"\"\"\n",
    "#in this method only the weights get saved and and we have to construct the model architecture to use the stores data\n",
    "import os.path\n",
    "if os.path.isfile('models/my_model_weights.h5') is False:\n",
    "    model.save_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the weights we have to create the model architecture \n",
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how we put the weights to the created model\n",
    "model2.load_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.13007364,  0.6753389 , -0.34804296, -0.348037  , -0.49796876,\n",
       "         -0.03822941,  0.6297927 , -0.3537085 ,  0.4325991 , -0.13074583,\n",
       "         -0.10107866,  0.8156631 , -0.24099678, -0.1948196 ,  0.36695257,\n",
       "         -0.54393464]], dtype=float32),\n",
       " array([ 0.22187598, -0.2164194 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.2147931 ,  0.        , -0.20724455,  0.        ,\n",
       "         0.        , -0.19489509,  0.        ,  0.        , -0.02618455,\n",
       "         0.        ], dtype=float32),\n",
       " array([[-1.81515008e-01, -2.98288345e-01,  5.00373766e-02,\n",
       "          5.41075468e-01,  4.40495521e-01, -1.57021061e-01,\n",
       "          8.25492740e-02,  4.77873057e-01, -5.20229377e-02,\n",
       "          3.70112024e-02, -1.79410517e-01,  2.98329219e-02,\n",
       "         -6.96748309e-03,  1.75323471e-01,  2.56481282e-02,\n",
       "         -1.75051391e-02, -1.63087487e-01,  3.20297420e-01,\n",
       "          1.80731937e-01,  5.09057343e-01,  1.68815285e-01,\n",
       "         -2.64495909e-01, -1.70324519e-01, -3.36136550e-01,\n",
       "          4.68193412e-01,  5.20707726e-01, -2.82632232e-01,\n",
       "          3.43943477e-01, -9.54168439e-02, -1.98337078e-01,\n",
       "          1.67474166e-01, -2.01672643e-01],\n",
       "        [-2.37008840e-01, -2.83063650e-01,  3.52923274e-02,\n",
       "         -8.27187970e-02, -3.19083065e-01,  6.08565584e-02,\n",
       "         -2.08295882e-01, -5.54424167e-01, -2.81467766e-01,\n",
       "         -1.93453670e-01,  3.65262121e-01,  5.72169185e-01,\n",
       "          3.57694864e-01, -1.37478188e-01,  1.07824914e-01,\n",
       "          1.38051301e-01, -1.82788178e-01, -1.63944170e-01,\n",
       "          6.66067719e-01, -2.63381600e-01, -1.41571254e-01,\n",
       "          1.04600132e-01, -3.07893336e-01,  3.08690369e-02,\n",
       "         -2.23646000e-01, -3.36527854e-01,  4.45354730e-01,\n",
       "         -1.52212173e-01,  1.33907199e-01, -2.82754630e-01,\n",
       "          5.66668153e-01,  4.20826048e-01],\n",
       "        [ 1.97827548e-01,  1.00794137e-02, -2.19633460e-01,\n",
       "          2.78076530e-03, -4.97310758e-02,  4.01887000e-02,\n",
       "          3.11397910e-02,  5.75421751e-02, -2.44158506e-02,\n",
       "         -4.48096097e-02,  5.75827956e-02,  1.70300335e-01,\n",
       "          2.47225970e-01,  1.96314126e-01, -2.41057962e-01,\n",
       "         -6.08558357e-02, -1.83103353e-01, -4.26698029e-02,\n",
       "          2.85687596e-01, -2.55625188e-01,  3.19159180e-01,\n",
       "         -3.17247510e-01, -2.17922300e-01,  3.08539897e-01,\n",
       "          1.64873809e-01,  1.12741381e-01,  3.17844361e-01,\n",
       "          6.61581457e-02, -2.68199533e-01, -3.16109776e-01,\n",
       "          4.05898690e-03, -8.60269368e-02],\n",
       "        [-2.77240783e-01,  2.32925147e-01, -1.94958508e-01,\n",
       "          1.98657721e-01, -5.97575605e-02,  1.85990840e-01,\n",
       "         -7.16055632e-02, -3.10992897e-01, -7.68203139e-02,\n",
       "         -1.80244371e-01,  1.41896725e-01, -2.27481455e-01,\n",
       "         -2.60925651e-01, -1.58749521e-02,  3.43624949e-02,\n",
       "         -2.91332603e-02,  2.20899194e-01,  1.18588239e-01,\n",
       "         -8.16004276e-02,  2.75235444e-01, -2.06986114e-01,\n",
       "          3.08401793e-01,  7.53254294e-02, -8.27755630e-02,\n",
       "          3.05846125e-01, -2.39386424e-01,  1.90238506e-01,\n",
       "          1.47763461e-01, -3.45445096e-01, -7.14207888e-02,\n",
       "          1.55989021e-01,  3.29517990e-01],\n",
       "        [ 1.00909919e-01, -3.47504795e-01,  6.35294616e-02,\n",
       "         -3.42357337e-01, -3.16868335e-01,  1.00131482e-01,\n",
       "         -3.29412252e-01,  1.20004565e-01,  1.82309836e-01,\n",
       "         -2.14281380e-02,  1.05146170e-02,  3.04037839e-01,\n",
       "          2.56140143e-01, -2.01030344e-01,  3.34591359e-01,\n",
       "         -9.43125784e-02, -1.92056954e-01, -3.38749290e-02,\n",
       "          3.14445764e-01,  2.93358654e-01, -1.79286703e-01,\n",
       "          5.38808703e-02, -3.42996538e-01,  8.86532068e-02,\n",
       "         -3.49362880e-01, -2.16719434e-01,  1.91038579e-01,\n",
       "         -8.76892209e-02,  2.28483349e-01,  1.18921548e-01,\n",
       "         -6.50849938e-03,  5.61532676e-02],\n",
       "        [ 2.59356767e-01,  2.37710327e-01,  3.25310528e-02,\n",
       "          5.31133711e-02, -3.67714465e-02,  1.97355300e-01,\n",
       "         -2.09153652e-01, -1.66205004e-01,  1.96439028e-03,\n",
       "          7.53331184e-02,  2.41841227e-01, -3.47779185e-01,\n",
       "          2.24447638e-01,  1.48609728e-01,  1.23770624e-01,\n",
       "         -1.27608180e-01,  1.82572633e-01,  2.77734131e-01,\n",
       "          2.99694747e-01,  1.24668002e-01, -1.00514591e-01,\n",
       "         -8.89963508e-02,  2.71130949e-01, -8.76949430e-02,\n",
       "         -2.75966436e-01,  2.74232537e-01, -1.18453965e-01,\n",
       "          1.38476491e-03,  2.38828093e-01, -3.45921099e-01,\n",
       "         -6.42676353e-02, -1.33858979e-01],\n",
       "        [ 7.50630200e-02, -2.93772548e-01,  3.33945364e-01,\n",
       "         -4.59924519e-01, -5.36665060e-02, -2.52593577e-01,\n",
       "          9.60448980e-02,  1.07574150e-01, -5.86061418e-01,\n",
       "         -1.18925415e-01,  5.36926270e-01,  4.93616611e-01,\n",
       "          5.05004883e-01, -3.81188780e-01,  3.20855677e-01,\n",
       "          4.87878531e-01,  2.71666676e-01, -4.66828108e-01,\n",
       "          4.60553497e-01, -3.17507386e-01, -2.98626602e-01,\n",
       "          6.74783945e-01,  1.77805722e-02, -3.21977735e-01,\n",
       "         -4.55537200e-01, -4.89816934e-01,  4.63059306e-01,\n",
       "         -6.28047526e-01, -1.89007789e-01, -2.51958936e-01,\n",
       "          6.26303375e-01,  1.11411586e-01],\n",
       "        [-2.94962943e-01,  1.40390903e-01, -1.81492582e-01,\n",
       "          1.97533578e-01,  2.88097888e-01,  2.80968815e-01,\n",
       "         -9.57908630e-02,  2.34236270e-01,  6.66590333e-02,\n",
       "         -3.06720138e-01,  3.32192034e-01,  7.81907439e-02,\n",
       "          1.33994699e-01, -1.58949763e-01, -1.61025241e-01,\n",
       "         -7.37007558e-02,  1.30319595e-02, -9.97420251e-02,\n",
       "          2.47397512e-01,  3.03023428e-01,  3.37599367e-01,\n",
       "          4.44711745e-02, -3.11297476e-02,  5.74712753e-02,\n",
       "         -2.86020160e-01, -1.35665059e-01,  8.95059109e-02,\n",
       "         -3.19875956e-01, -7.99078941e-02,  2.33424306e-02,\n",
       "         -3.23585302e-01,  7.34515786e-02],\n",
       "        [ 1.19360030e-01, -2.77238429e-01, -2.98995197e-01,\n",
       "         -5.12874424e-01, -2.17713848e-01,  2.98612505e-01,\n",
       "          1.44586861e-01, -2.84657240e-01, -4.99205202e-01,\n",
       "          4.39448357e-02,  6.61384046e-01,  6.24514520e-01,\n",
       "          1.44228321e-02, -8.34474504e-01,  1.45560533e-01,\n",
       "          5.75874388e-01,  5.60361743e-02, -5.01032472e-01,\n",
       "          6.50615811e-01, -7.26414442e-01, -8.28379929e-01,\n",
       "          4.96661186e-01,  1.37876734e-01,  2.39125937e-01,\n",
       "         -7.63537228e-01, -3.43320578e-01,  2.25657865e-01,\n",
       "         -4.58445877e-01, -1.28705770e-01, -2.30229527e-01,\n",
       "          1.43873110e-01,  2.82436609e-01],\n",
       "        [-1.14925012e-01, -1.13457382e-01,  3.47866714e-02,\n",
       "          6.76105320e-02,  1.17752731e-01, -1.23073354e-01,\n",
       "          3.09184402e-01,  1.42078280e-01, -5.18014133e-02,\n",
       "          3.38721126e-01,  1.92853779e-01, -1.47752181e-01,\n",
       "         -9.49999988e-02,  2.93417007e-01, -2.84150243e-01,\n",
       "          2.12802798e-01, -2.87943900e-01, -3.29233378e-01,\n",
       "         -6.88672066e-03, -2.49040410e-01, -2.79333472e-01,\n",
       "          1.30165309e-01,  1.72542542e-01,  2.97504753e-01,\n",
       "          7.61204958e-02, -1.54029444e-01, -2.22343341e-01,\n",
       "          2.80848950e-01,  1.21044397e-01,  5.00621796e-02,\n",
       "         -1.08464077e-01,  1.63578480e-01],\n",
       "        [ 7.19306767e-02, -2.72363424e-04,  7.79940188e-02,\n",
       "         -8.67136121e-02,  2.74647743e-01,  2.06999511e-01,\n",
       "         -2.82511175e-01, -8.10691118e-02,  1.47091836e-01,\n",
       "          5.62662184e-02,  3.27897102e-01, -1.74061000e-01,\n",
       "          1.77414566e-01,  3.26944500e-01,  2.19664127e-01,\n",
       "          1.32851928e-01, -1.49917766e-01,  4.85388339e-02,\n",
       "         -1.93829134e-01, -3.96134853e-02, -1.87451392e-01,\n",
       "         -1.63827330e-01, -2.68367529e-02, -1.94113716e-01,\n",
       "         -2.00901046e-01, -3.21659774e-01,  3.20066422e-01,\n",
       "          1.54461056e-01,  1.29138291e-01,  6.36407435e-02,\n",
       "          3.95423174e-03,  3.18837851e-01],\n",
       "        [-3.11260045e-01,  1.71482459e-01, -2.53001660e-01,\n",
       "         -4.56323743e-01, -2.16294602e-01, -9.35951546e-02,\n",
       "         -1.70505911e-01, -5.04349291e-01, -8.52707122e-03,\n",
       "         -3.42660815e-01,  4.40152794e-01,  5.73022604e-01,\n",
       "          3.90993774e-01, -1.50372729e-01, -2.41456360e-01,\n",
       "          1.02972187e-01, -1.13415137e-01, -9.31019187e-02,\n",
       "          1.64235622e-01, -4.59410280e-01, -5.64351380e-02,\n",
       "          6.68219984e-01,  2.53527522e-01, -1.42538533e-01,\n",
       "         -6.28594775e-03, -2.53574818e-01,  6.11641228e-01,\n",
       "         -1.44701004e-01, -1.62090451e-01,  2.37826392e-01,\n",
       "          5.96300840e-01,  3.11850518e-01],\n",
       "        [-8.60001445e-02,  1.56143457e-01,  2.45985299e-01,\n",
       "          1.10632181e-02, -1.79432362e-01,  2.42689461e-01,\n",
       "          2.23703682e-02,  3.46682280e-01, -3.12308908e-01,\n",
       "          2.66373724e-01,  2.63231188e-01,  2.84681886e-01,\n",
       "         -2.84915268e-02, -2.98832774e-01, -8.89629722e-02,\n",
       "         -4.52777743e-02,  3.16674143e-01, -1.27341479e-01,\n",
       "          1.39947772e-01, -2.83125252e-01, -2.25599945e-01,\n",
       "         -8.63986909e-02,  8.30585361e-02,  2.37361044e-01,\n",
       "          7.36187398e-02,  2.60842711e-01, -2.35061347e-02,\n",
       "         -1.74541473e-01,  3.38512659e-02, -3.04839045e-01,\n",
       "          1.03654623e-01, -4.39032018e-02],\n",
       "        [-6.56991899e-02, -3.38970840e-01,  3.14449936e-01,\n",
       "         -1.80871263e-01,  1.27904654e-01,  3.96382809e-02,\n",
       "          3.46636146e-01,  1.55485719e-01,  1.86318964e-01,\n",
       "         -1.31106541e-01,  2.34408349e-01,  2.01082975e-01,\n",
       "          3.41844290e-01, -6.91668689e-02,  2.28526980e-01,\n",
       "          2.77180105e-01, -7.01602697e-02,  2.73446470e-01,\n",
       "          1.51799649e-01,  3.29515040e-02, -1.64998084e-01,\n",
       "         -2.69886076e-01,  1.52115524e-02,  6.83174133e-02,\n",
       "          9.21257734e-02,  1.54320508e-01,  3.20679873e-01,\n",
       "         -1.87844709e-01,  2.45780259e-01, -6.24794066e-02,\n",
       "          2.08039135e-01, -6.88863397e-02],\n",
       "        [-9.71367955e-03, -1.79302424e-01,  3.54999900e-02,\n",
       "         -2.22661868e-01, -1.61990657e-01,  1.74756035e-01,\n",
       "         -1.75802857e-01, -5.51283993e-02, -6.35406375e-02,\n",
       "         -1.86355695e-01,  4.23041284e-02,  3.13930392e-01,\n",
       "         -1.14375509e-01, -3.96287888e-02, -3.13968033e-01,\n",
       "          1.81711033e-01, -2.49799475e-01, -1.01704285e-01,\n",
       "          3.03788096e-01,  5.42286634e-02, -7.68841729e-02,\n",
       "          3.50601912e-01, -2.81396300e-01,  1.41443908e-01,\n",
       "          7.23119378e-02,  5.66284955e-02, -3.62287760e-02,\n",
       "          1.28230587e-01, -2.12596029e-01,  2.03469425e-01,\n",
       "          1.24696590e-01,  3.50168794e-01],\n",
       "        [ 9.95768309e-02,  1.06828094e-01,  8.39072168e-02,\n",
       "         -2.91584551e-01,  3.19848984e-01,  1.55648202e-01,\n",
       "         -2.66398937e-01, -3.42480481e-01, -3.53304803e-01,\n",
       "         -2.45058537e-01,  1.56676799e-01, -2.71733284e-01,\n",
       "          3.77914906e-02,  1.09788507e-01, -3.07094485e-01,\n",
       "          1.38224810e-01, -8.89809430e-02,  3.49785775e-01,\n",
       "         -2.11364165e-01, -1.81148663e-01,  1.33760691e-01,\n",
       "          2.91749150e-01,  1.90274566e-01,  3.47698778e-01,\n",
       "         -3.42513680e-01,  2.55077511e-01,  2.88144857e-01,\n",
       "         -2.27817535e-01,  2.07381845e-02,  2.41681546e-01,\n",
       "          2.03543633e-01, -1.77543506e-01]], dtype=float32),\n",
       " array([ 0.        , -0.00120307, -0.01467855,  0.27954414,  0.14620827,\n",
       "        -0.00169673, -0.01962761,  0.24248528,  0.24462692, -0.00892927,\n",
       "        -0.13588877, -0.18997945, -0.13358663,  0.20807403, -0.00862299,\n",
       "        -0.11481256,  0.        ,  0.17676392, -0.17963547,  0.257298  ,\n",
       "         0.16679433, -0.16304906, -0.00120322,  0.        ,  0.12256607,\n",
       "         0.20383763, -0.13369381,  0.1698565 ,  0.        , -0.00301855,\n",
       "        -0.17600746, -0.1319024 ], dtype=float32),\n",
       " array([[ 0.25722983,  0.0414564 ],\n",
       "        [ 0.00445899,  0.17490438],\n",
       "        [-0.23464979, -0.11273222],\n",
       "        [ 0.80714417, -0.34850886],\n",
       "        [ 0.5451453 , -0.38367158],\n",
       "        [-0.08709396,  0.14793949],\n",
       "        [-0.28287202,  0.08659507],\n",
       "        [ 0.7428561 , -0.96756697],\n",
       "        [ 0.8176907 , -0.53931427],\n",
       "        [ 0.07030135, -0.01792309],\n",
       "        [-0.69328445,  0.69991225],\n",
       "        [-0.5654918 ,  0.09698159],\n",
       "        [-0.47060832,  0.044989  ],\n",
       "        [ 0.22478792, -0.87685716],\n",
       "        [ 0.22483605, -0.06286658],\n",
       "        [-0.05307632,  0.52061695],\n",
       "        [ 0.19895777, -0.01738876],\n",
       "        [ 0.6842252 , -0.5609169 ],\n",
       "        [-0.3592117 ,  0.37499857],\n",
       "        [ 0.85735875, -0.36416617],\n",
       "        [ 0.57320637, -0.5027158 ],\n",
       "        [-0.5529703 ,  0.19074975],\n",
       "        [-0.41292515, -0.15654097],\n",
       "        [-0.2847247 , -0.2217881 ],\n",
       "        [ 0.5873477 , -0.31860325],\n",
       "        [ 0.75621843, -0.26584467],\n",
       "        [-0.22356717,  0.7575335 ],\n",
       "        [ 0.6442622 , -0.7504596 ],\n",
       "        [-0.07021984,  0.06443337],\n",
       "        [ 0.31608906,  0.37572256],\n",
       "        [-0.20724125,  0.6229601 ],\n",
       "        [-0.36645836,  0.8374325 ]], dtype=float32),\n",
       " array([ 0.11519522, -0.11519521], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
